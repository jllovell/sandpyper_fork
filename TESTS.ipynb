{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "from sandpyper.profile import extract_from_folder\n",
    "from sandpyper.space import create_transects\n",
    "import numpy as np\n",
    "import math\n",
    "from shapely.geometry import (\n",
    "    MultiLineString,\n",
    "    LineString,\n",
    "    Point)\n",
    "\n",
    "\n",
    "\n",
    "def getAngle(pt1, pt2):\n",
    "    \"\"\"Helper function to return the angle of two points (pt1 and pt2) coordinates in degrees.\n",
    "    Source: http://wikicode.wikidot.com/get-angle-of-line-between-two-points\"\"\"\n",
    "\n",
    "    x_diff = pt2[0] - pt1[0]\n",
    "    y_diff = pt2[1] - pt1[1]\n",
    "    return math.degrees(math.atan2(y_diff, x_diff))\n",
    "\n",
    "\n",
    "def getPoint1(pt, bearing, dist):\n",
    "    \"\"\"Helper function to return the point coordinates at a determined distance (dist) and bearing from a starting point (pt).\"\"\"\n",
    "\n",
    "    angle = bearing + 90\n",
    "    bearing = math.radians(angle)\n",
    "    x = pt[0] + dist * math.cos(bearing)\n",
    "    y = pt[1] + dist * math.sin(bearing)\n",
    "    return Point(x, y)\n",
    "\n",
    "\n",
    "def getPoint2(pt, bearing, dist):\n",
    "    bearing = math.radians(bearing)\n",
    "    x = pt[0] + dist * math.cos(bearing)\n",
    "    y = pt[1] + dist * math.sin(bearing)\n",
    "    return Point(x, y)\n",
    "\n",
    "\n",
    "def split_transects(geom, side=\"left\"):\n",
    "    \"\"\"Helper function to split transects geometry normal to shoreline, retaining only their left (default) or right side.\"\"\"\n",
    "\n",
    "    side_dict = {\"left\": 0, \"right\": 1}\n",
    "    snapped = snap(geom, geom.centroid, 0.001)\n",
    "    result = split(snapped, geom.centroid)\n",
    "    return result[side_dict[side]]\n",
    "\n",
    "\n",
    "def create_transects(baseline, sampling_step, tick_length, location, crs, side=\"both\"):\n",
    "    \"\"\"Creates a GeoDataFrame with transects normal to the baseline, with defined spacing and length.\n",
    "\n",
    "    Args:\n",
    "        baseline (str): Local path of the timeseries files, as returned by the multitemporal extraction.\n",
    "        list_loc_codes (list): list of strings containing location codes.\n",
    "    Returns:\n",
    "        Geodataframe.\n",
    "    \"\"\"\n",
    "    if side != \"both\":\n",
    "        tick_length = 2 * tick_length\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if sampling_step == 0 or sampling_step >= baseline.length.values[0]:\n",
    "        raise ValueError(f\"Sampling step provided ({sampling_step}) cannot be zero or equal or greater than the baseline length ({baseline.length.values[0]}).\")\n",
    "    else:\n",
    "        try:\n",
    "            dists = np.arange(0, baseline.geometry.length[0], sampling_step)\n",
    "        except BaseException:\n",
    "            try:\n",
    "                dists = np.arange(0, baseline.geometry.length, sampling_step)\n",
    "            except BaseException:\n",
    "                dists = np.arange(0, baseline.geometry.length.values[0], sampling_step)\n",
    "\n",
    "        points_coords = []\n",
    "        try:\n",
    "            for j in [baseline.geometry.interpolate(i) for i in dists]:\n",
    "                points_coords.append((j.geometry.x[0], j.geometry.y[0]))\n",
    "        except BaseException:\n",
    "            for j in [baseline.geometry.interpolate(i) for i in dists]:\n",
    "                points_coords.append((j.geometry.x, j.geometry.y))\n",
    "\n",
    "                # create transects as Shapely linestrings\n",
    "\n",
    "        ticks = []\n",
    "        for num, pt in enumerate(points_coords, 1):\n",
    "            # start chainage 0\n",
    "            if num == 1:\n",
    "                angle = getAngle(pt, points_coords[num])\n",
    "                line_end_1 = getPoint1(pt, angle, tick_length / 2)\n",
    "                angle = getAngle([line_end_1.x, line_end_1.y], pt)\n",
    "                line_end_2 = getPoint2([line_end_1.x, line_end_1.y], angle, tick_length)\n",
    "                tick = LineString(\n",
    "                    [(line_end_1.x, line_end_1.y), (line_end_2.x, line_end_2.y)]\n",
    "                )\n",
    "\n",
    "            ## everything in between\n",
    "            if num < len(points_coords) - 1:\n",
    "                angle = getAngle(pt, points_coords[num])\n",
    "                line_end_1 = getPoint1(points_coords[num], angle, tick_length / 2)\n",
    "                angle = getAngle([line_end_1.x, line_end_1.y], points_coords[num])\n",
    "                line_end_2 = getPoint2([line_end_1.x, line_end_1.y], angle, tick_length)\n",
    "                tick = LineString(\n",
    "                    [(line_end_1.x, line_end_1.y), (line_end_2.x, line_end_2.y)]\n",
    "                )\n",
    "\n",
    "            # end chainage\n",
    "            if num == len(points_coords):\n",
    "                angle = getAngle(points_coords[num - 2], pt)\n",
    "                line_end_1 = getPoint1(pt, angle, tick_length / 2)\n",
    "                angle = getAngle([line_end_1.x, line_end_1.y], pt)\n",
    "                line_end_2 = getPoint2([line_end_1.x, line_end_1.y], angle, tick_length)\n",
    "                tick = LineString(\n",
    "                    [(line_end_1.x, line_end_1.y), (line_end_2.x, line_end_2.y)]\n",
    "                )\n",
    "\n",
    "            ticks.append(tick)\n",
    "\n",
    "        gdf_transects = gpd.GeoDataFrame(\n",
    "            {\n",
    "                \"tr_id\": range(len(ticks)),\n",
    "                \"geometry\": ticks,\n",
    "                \"location\": [location for i in range(len(ticks))],\n",
    "            },\n",
    "            crs=crs,\n",
    "        )\n",
    "\n",
    "        # clip the transects\n",
    "\n",
    "        if side == \"both\":\n",
    "            pass\n",
    "        else:\n",
    "\n",
    "            gdf_transects[\"geometry\"] = gdf_transects.geometry.apply(\n",
    "                split_transects, **{\"side\": side}\n",
    "            )\n",
    "\n",
    "        return gdf_transects\n",
    "    \n",
    "from sandpyper.outils import (\n",
    "    cross_ref,\n",
    "    getListOfFiles,\n",
    "    getDate,\n",
    "    getLoc,\n",
    "    getCrs_from_raster_path,\n",
    ")\n",
    "from sandpyper.profile import extract_from_folder, get_profiles\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from shapely.geometry import (\n",
    "    MultiLineString,\n",
    "    LineString,\n",
    "    Point,\n",
    "    Polygon,\n",
    "    MultiPolygon,\n",
    "    mapping,\n",
    "    box,\n",
    ")\n",
    "from shapely.ops import split, snap, unary_union\n",
    "\n",
    "\n",
    "loc_codes=[\"mar\",\"leo\"]\n",
    "loc_search_dict = {'leo': ['St', 'Leonards', 'leonards', 'leo'], 'mar': ['Marengo', 'marengo', 'mar'] }\n",
    "crs_dict_string = {'mar': {'init': 'epsg:32754'}, 'leo':{'init': 'epsg:32755'} }\n",
    "import math\n",
    "\n",
    "# CASE FIXTURES - create transects\n",
    "path_to_shoreline_mar=r'C:\\my_packages\\doc_data\\test_data\\shorelines\\mar_shoreline_short.gpkg' # Marengo shoreline\n",
    "path_to_shoreline_leo=r'C:\\my_packages\\doc_data\\test_data\\shorelines\\leo_shoreline_short.gpkg' # leo shoreline\n",
    "\n",
    "path_to_dsm=r'C:\\my_packages\\sandpyper\\tests\\test_data\\dsm_1m' # Marengo shoreline\n",
    "path_to_ortho=r'C:\\my_packages\\sandpyper\\tests\\test_data\\orthos_1m' # Marengo shoreline\n",
    "transect_folder=r'C:\\my_packages\\sandpyper\\tests\\test_data\\transects'\n",
    "\n",
    "mar_shoreline=gpd.read_file(path_to_shoreline_mar)\n",
    "leo_shoreline=gpd.read_file(path_to_shoreline_leo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-330-cb130cfb5501>:430: UserWarning: WARNING: add_terrain increases running time to up to 45 minutes.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e12d3fbd114e61ba96b5220f8f292f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in leo at date: 20180606 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009629b8aba64cf79cb611af1c9bd3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in leo at date: 20180713 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f136a02f934d44818d3ed7ea874efea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in leo at date: 20180920 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b637a54ff3104f9d97476f5390b2ffde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in leo at date: 20190211 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8502de6d3d4845e6a0f31eb26a811e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in leo at date: 20190328 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaddede04374f66970011dea2d54a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in leo at date: 20190731 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1c86f0f2df4a0688592a2af9fcaaf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in mar at date: 20180601 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d390a025fe447a9a40e1f6b61018a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in mar at date: 20180621 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4592908408a649f0b2f640465437f6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in mar at date: 20180727 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e3a815cc034615ab36ac864f6ba08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in mar at date: 20180925 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad0eb97b16349fd9a5a50c614a69596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in mar at date: 20181113 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed10604a8c546d2bc39e7aed0f79433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in mar at date: 20181211 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a29425428b42659acbb133307cdf5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in mar at date: 20190205 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c353d86fb24a36afc027d4bececd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in mar at date: 20190313 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5895814465ee495c8b6a1ee4a9d83396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n",
      "Computing slope DSM in degrees in mar at date: 20190516 . . .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4374a6811a3544eb8627c9ac65e884a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction succesfull\n",
      "Number of points extracted:32805\n",
      "Time for processing=39.51909518241882 seconds\n",
      "First 10 rows are printed below\n",
      "Number of points outside the raster extents: 9066\n",
      "The extraction assigns NaN.\n",
      "Number of points in NoData areas within the raster extents: 250\n",
      "The extraction assigns NaN.\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gdf=extract_from_folder(dataset_folder=path_to_dsm,\n",
    "                        transect_folder=transect_folder,\n",
    "                        mode=\"dsm\",sampling_step=1,\n",
    "                        list_loc_codes=loc_codes,\n",
    "                        add_xy=True,\n",
    "                       add_slope=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Profile module.\"\"\"\n",
    "\n",
    "from rasterio.windows import Window, from_bounds\n",
    "from rasterio.transform import rowcol\n",
    "import rasterio as ras\n",
    "import numpy as np\n",
    "import richdem as rd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sandpyper.outils import (\n",
    "    create_id,\n",
    "    filter_filename_list,\n",
    "    getListOfFiles,\n",
    "    getDate,\n",
    "    getLoc,\n",
    ")\n",
    "\n",
    "\n",
    "def get_terrain_info(x_coord, y_coord, rdarray):\n",
    "    \"\"\"\n",
    "    Returns the value of the rdarray rasters.\n",
    "\n",
    "    Args:\n",
    "        x_coord, y_coord (float): Projected coordinates of pixel to extract value.\n",
    "        rdarray (rdarray): rdarray dataset.\n",
    "\n",
    "    Returns:\n",
    "        rdarray pixel value.\n",
    "    \"\"\"\n",
    "\n",
    "    geotransform = rdarray.geotransform\n",
    "\n",
    "    xOrigin = geotransform[0]  # top-left X\n",
    "    yOrigin = geotransform[3]  # top-left y\n",
    "    pixelWidth = geotransform[1]  # horizontal pixel resolution\n",
    "    pixelHeight = geotransform[5]  # vertical pixel resolution\n",
    "    px = int((x_coord - xOrigin) / pixelWidth)  # transform geographic to image coords\n",
    "    py = int((y_coord - yOrigin) / pixelHeight)  # transform geographic to image coords\n",
    "\n",
    "    try:\n",
    "        return rdarray[py, px]\n",
    "    except BaseException:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_elevation(x_coord, y_coord, raster, bands, transform):\n",
    "    \"\"\"\n",
    "    Returns the value of the raster at a specified location and band.\n",
    "\n",
    "    Args:\n",
    "        x_coord, y_coord (float): Projected coordinates of pixel to extract value.\n",
    "        raster (rasterio open file): Open raster object, from rasterio.open(raster_filepath).\n",
    "        bands (int): number of bands.\n",
    "        transform (Shapely Affine obj): Geotransform of the raster.\n",
    "    Returns:\n",
    "        raster pixel value.\n",
    "    \"\"\"\n",
    "    elevation = []\n",
    "    row, col = rowcol(transform, x_coord, y_coord, round)\n",
    "\n",
    "    for j in np.arange(bands):  # we could iterate thru multiple bands\n",
    "\n",
    "        try:\n",
    "            data_z = raster.read(1, window=Window(col, row, 1, 1))\n",
    "            elevation.append(data_z[0][0])\n",
    "        except BaseException:\n",
    "            elevation.append(np.nan)\n",
    "\n",
    "    return elevation\n",
    "\n",
    "\n",
    "def get_raster_px(x_coord, y_coord, raster, bands=None, transform=None):\n",
    "\n",
    "    if isinstance(raster, richdem.rdarray):\n",
    "        transform = rdarray.geotransform\n",
    "\n",
    "        xOrigin = transform[0]  # top-left X\n",
    "        yOrigin = transform[3]  # top-left y\n",
    "        pixelWidth = transform[1]  # horizontal pixel resolution\n",
    "        pixelHeight = transform[5]  # vertical pixel resolution\n",
    "        px = int(\n",
    "            (x_coord - xOrigin) / pixelWidth\n",
    "        )  # transform geographic to image coords\n",
    "        py = int(\n",
    "            (y_coord - yOrigin) / pixelHeight\n",
    "        )  # transform geographic to image coords\n",
    "\n",
    "        try:\n",
    "            return rdarray[py, px]\n",
    "        except BaseException:\n",
    "            return np.nan\n",
    "\n",
    "    else:\n",
    "        if bands == None:\n",
    "            bands = raster.count()\n",
    "\n",
    "        if bands == 1:\n",
    "            try:\n",
    "                px_data = raster.read(1, window=Window(col, row, 1, 1))\n",
    "                return px_data[0][0]\n",
    "            except BaseException:\n",
    "                return np.nan\n",
    "        elif bands > 1:\n",
    "            px_data = []\n",
    "            for band in range(1, bands + 1):\n",
    "                try:\n",
    "                    px_data_band = raster.read(band, window=Window(col, row, 1, 1))\n",
    "                    px_data.append(px_data_band[0][0])\n",
    "                except BaseException:\n",
    "                    px_data.append(np.nan)\n",
    "\n",
    "            return px_data\n",
    "\n",
    "\n",
    "def get_profiles(\n",
    "    dsm,\n",
    "    transect_file,\n",
    "    transect_index,\n",
    "    step,\n",
    "    location,\n",
    "    date_string,\n",
    "    add_xy=False,\n",
    "    add_terrain=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a tidy GeoDataFrame of profile data, extracting raster information\n",
    "    at a user-defined (step) meters gap along each transect.\n",
    "\n",
    "    Args:\n",
    "    dsm (str): path to the DSM raster.\n",
    "    transect_file (str): path to the transect file.\n",
    "    transect_index (int): index of the transect to extract information from.\n",
    "    step (int,float): sampling distance from one point to another in meters along the transect.\n",
    "    location (str): location code\n",
    "    date_string: raw format of the survey date (20180329)\n",
    "    add_xy (bool): True to add X and Y coordinates fields.\n",
    "    add_terrain (bool): True to add slope in degrees. Default to False.\n",
    "\n",
    "    Returns:\n",
    "    gdf (GeoDataFrame) : Profile data extracted from the raster.\n",
    "    \"\"\"\n",
    "\n",
    "    ds = ras.open(dsm, \"r\")\n",
    "    bands = ds.count  # get raster bands. One, in a classic DEM\n",
    "    transform = ds.transform  # get geotransform info\n",
    "\n",
    "    # index each transect and store it a \"line\" object\n",
    "    line = transect_file.loc[transect_index]\n",
    "    length_m = line.geometry.length\n",
    "\n",
    "    # Creating empty lists of coordinates, elevations and distance (from start\n",
    "    # to end points along each transect lines)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    slopes = []\n",
    "\n",
    "    # The \"distance\" object is and empty list which will contain the x variable\n",
    "    # which is the displacement from the shoreward end of the transects toward\n",
    "    # the foredunes.\n",
    "\n",
    "    distance = []\n",
    "    tr_count = 0  # a variable used as \"counter\", to stop the FOR loop\n",
    "    # when has gone thru all the transects\n",
    "\n",
    "    for currentdistance in np.arange(0, int(length_m), step):\n",
    "\n",
    "        # creation of the point on the line\n",
    "        point = line.geometry.interpolate(currentdistance)\n",
    "        xp, yp = (\n",
    "            point.x,\n",
    "            point.y,\n",
    "        )  # storing point xy coordinates into xp,xy objects, respectively\n",
    "        x.append(xp)  # see below\n",
    "        y.append(\n",
    "            yp\n",
    "        )  # append point coordinates to previously created and empty x,y lists\n",
    "        # extraction of the elevation value from DSM\n",
    "        z.append(get_elevation(xp, yp, ds, bands, transform)[0])\n",
    "        if str(type(add_terrain)) == \"<class 'richdem.rdarray'>\":\n",
    "            slopes.append(get_terrain_info(xp, yp, add_terrain))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # append the distance value (currentdistance) to distance list\n",
    "        distance.append(currentdistance)\n",
    "        tr_count += 1  # increment by 1 the counter, and repeat!\n",
    "\n",
    "    # Below, the empty lists tr_id_list and the date_list will be filled by strings\n",
    "    # containing the transect_id of every point as stored in the original dataset\n",
    "    # and a label with the date as set in the data setting section, after the input.\n",
    "\n",
    "    tr_id_list = []\n",
    "    date_list = []\n",
    "    tr_counter = 0  # same mechanism as previous FOR loop\n",
    "\n",
    "    while tr_counter <= tr_count:\n",
    "        tr_id_list.append((int(line.name)))\n",
    "        date_list.append(str(date_string))\n",
    "        tr_counter += 1\n",
    "\n",
    "    # Here below is to combine distance, elevation, profile_id and date into\n",
    "    # an array first (profile_x_z), then multiple Pandas series.\n",
    "\n",
    "    if str(type(add_terrain)) == \"<class 'richdem.rdarray'>\":\n",
    "        profile_x_z = tuple(zip(distance, z, tr_id_list, date_list, slopes))\n",
    "\n",
    "        ds1 = pd.Series((v[0] for v in profile_x_z))\n",
    "        ds2 = pd.Series((v[1] for v in profile_x_z))\n",
    "        ds3 = pd.Series((v[2] for v in profile_x_z))\n",
    "        ds4 = pd.Series((v[3] for v in profile_x_z))\n",
    "        ds5 = pd.Series((v[4] for v in profile_x_z))\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {\"distance\": ds1, \"z\": ds2, \"tr_id\": ds3, \"raw_date\": ds4, \"slope\": ds5}\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        profile_x_z = tuple(zip(distance, z, tr_id_list, date_list))\n",
    "\n",
    "        ds1 = pd.Series((v[0] for v in profile_x_z))\n",
    "        ds2 = pd.Series((v[1] for v in profile_x_z))\n",
    "        ds3 = pd.Series((v[2] for v in profile_x_z))\n",
    "        ds4 = pd.Series((v[3] for v in profile_x_z))\n",
    "\n",
    "        df = pd.DataFrame({\"distance\": ds1, \"z\": ds2, \"tr_id\": ds3, \"raw_date\": ds4})\n",
    "\n",
    "    # Here finally a Pandas dataframe is created containing all the Series previously created\n",
    "    # and coordinates of the points are added to a new column called \"coordinates\".\n",
    "    # At last, we create a Pandas GeoDataFrame and set the geometry column = coordinates\n",
    "\n",
    "    df[\"coordinates\"] = list(zip(x, y))\n",
    "    df[\"coordinates\"] = df[\"coordinates\"].apply(Point)\n",
    "    df[\"location\"] = location\n",
    "    df[\"survey_date\"] = pd.to_datetime(\n",
    "        date_string, yearfirst=True, dayfirst=False, format=\"%Y%m%d\"\n",
    "    )\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=\"coordinates\")\n",
    "\n",
    "    # The proj4 info (coordinate reference system) is gathered with\n",
    "    # Geopandas and applied to the newly created one.\n",
    "    gdf.crs = str(transect_file.crs)\n",
    "\n",
    "    # Transforming non-hashable Shapely coordinates to hashable strings and\n",
    "    # store them into a variable\n",
    "\n",
    "    # Let's create unique IDs from the coordinates values, so that the Ids\n",
    "    # follows the coordinates\n",
    "    gdf[\"point_id\"] = [create_id(gdf.iloc[i]) for i in range(0, gdf.shape[0])]\n",
    "\n",
    "    if bool(add_xy):\n",
    "        # Adding long/lat fields\n",
    "        gdf[\"x\"] = gdf.coordinates.x\n",
    "        gdf[\"y\"] = gdf.coordinates.y\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def get_dn(x_coord, y_coord, raster, bands, transform):\n",
    "    \"\"\"\n",
    "    Returns the value of the raster at a specified location and band.\n",
    "\n",
    "    Args:\n",
    "        x_coord, y_coord (float): Projected coordinates of pixel to extract value.\n",
    "        raster (rasterio open file): Open raster object, from rasterio.open(raster_filepath).\n",
    "        bands (int): number of bands.\n",
    "        transform (Shapely Affine obj): Geotransform of the raster.\n",
    "    Returns:\n",
    "        raster pixel value.\n",
    "    \"\"\"\n",
    "    # Let's create an empty list where we will store the elevation (z) from points\n",
    "    # With GDAL, we extract 4 components of the geotransform (gt) of our north-up image.\n",
    "\n",
    "    dn_val = []\n",
    "    row, col = rowcol(transform, x_coord, y_coord, round)\n",
    "\n",
    "    for j in range(1, 4):  # we could iterate thru multiple bands\n",
    "\n",
    "        try:\n",
    "            data = raster.read(j, window=Window(col, row, 1, 1))\n",
    "            dn_val.append(data[0][0])\n",
    "        except BaseException:\n",
    "            dn_val.append(np.nan)\n",
    "    return dn_val\n",
    "\n",
    "\n",
    "def get_profile_dn(\n",
    "    ortho, transect_file, transect_index, step, location, date_string, add_xy=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a tidy GeoDataFrame of profile data, extracting raster information\n",
    "    at a user-defined (step) meters gap along each transect.\n",
    "\n",
    "    Args:\n",
    "    ortho (str): path to the DSM raster.\n",
    "    transect_file (str): path to the transect file.\n",
    "    transect_index (int): index of the transect to extract information from.\n",
    "    step (int,float): sampling distance from one point to another in meters along the transect.\n",
    "    location (str): location code\n",
    "    date_string: raw format of the survey date (20180329)\n",
    "    add_xy (bool): True to add X and Y coordinates fields.\n",
    "\n",
    "    Returns:\n",
    "    gdf (GeoDataFrame) : Profile data extracted from the raster.\n",
    "    \"\"\"\n",
    "\n",
    "    ds = ras.open(ortho, \"r\")\n",
    "\n",
    "    bands = ds.count\n",
    "\n",
    "    transform = ds.transform\n",
    "\n",
    "    line = transect_file.loc[transect_index]\n",
    "\n",
    "    length_m = line.geometry.length\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    dn = []\n",
    "    distance = []\n",
    "    for currentdistance in np.arange(0, int(length_m), step):\n",
    "        # creation of the point on the line\n",
    "        point = line.geometry.interpolate(currentdistance)\n",
    "        xp, yp = (\n",
    "            point.x,\n",
    "            point.y,\n",
    "        )  # storing point xy coordinates into xp,xy objects, respectively\n",
    "        x.append(xp)  # see below\n",
    "        y.append(\n",
    "            yp\n",
    "        )  # append point coordinates to previously created and empty x,y lists\n",
    "        dn.append(get_dn(xp, yp, ds, bands, transform))\n",
    "\n",
    "        distance.append(currentdistance)\n",
    "\n",
    "    dn1 = pd.Series((v[0] for v in dn))\n",
    "    dn2 = pd.Series((v[1] for v in dn))\n",
    "    dn3 = pd.Series((v[2] for v in dn))\n",
    "    df = pd.DataFrame({\"distance\": distance, \"band1\": dn1, \"band2\": dn2, \"band3\": dn3})\n",
    "    df[\"coordinates\"] = list(zip(x, y))\n",
    "    df[\"coordinates\"] = df[\"coordinates\"].apply(Point)\n",
    "    df[\"location\"] = location\n",
    "    df[\"survey_date\"] = pd.to_datetime(date_string, format=\"%Y%m%d\")\n",
    "    df[\"raw_date\"] = date_string\n",
    "    df[\"tr_id\"] = transect_index\n",
    "    gdf_rgb = gpd.GeoDataFrame(df, geometry=\"coordinates\")\n",
    "\n",
    "    # Last touch, the proj4 info (coordinate reference system) is gathered with\n",
    "    # Geopandas and applied to the newly created one.\n",
    "    gdf_rgb.crs = str(transect_file.crs)\n",
    "\n",
    "    # Let's create unique IDs from the coordinates values, so that the Ids\n",
    "    # follows the coordinates\n",
    "    gdf_rgb[\"point_id\"] = [\n",
    "        create_id(gdf_rgb.iloc[i]) for i in range(0, gdf_rgb.shape[0])\n",
    "    ]\n",
    "\n",
    "    if bool(add_xy):\n",
    "        # Adding long/lat fields\n",
    "        gdf_rgb[\"x\"] = gdf_rgb.coordinates.x\n",
    "        gdf_rgb[\"y\"] = gdf_rgb.coordinates.y\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return gdf_rgb\n",
    "\n",
    "\n",
    "def extract_from_folder(\n",
    "    dataset_folder,\n",
    "    transect_folder,\n",
    "    list_loc_codes,\n",
    "    mode,\n",
    "    sampling_step,\n",
    "    add_xy=False,\n",
    "    add_slope=False,\n",
    "    default_nan_values=-10000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper to extract profiles from all rasters inside a folder.\n",
    "\n",
    "    Warning: The folders must contain the geotiffs and geopackages only.\n",
    "\n",
    "    Args:\n",
    "        dataset_folder (str): Path of the directory containing the datasets (geotiffs, .tiff).\n",
    "        transect_folder (str): Path of the directory containing the transects (geopackages, .gpkg).\n",
    "        list_loc_codes (list): list of strings containing location codes.\n",
    "        mode (str): If 'dsm', extract from DSMs. If 'ortho', extracts from orthophotos.\n",
    "        sampling_step (float): Distance along-transect to sample points at. In meters.\n",
    "        add_xy (bool): If True, adds extra columns with long and lat coordinates in the input CRS.\n",
    "        add_slope (bool): If True, computes slope raster in degrees (increased procesing time)\n",
    "        and extract slope values across transects.\n",
    "        nan_values (int): Value used for NoData in the raster format.\n",
    "        In Pix4D, this is -10000 (Default).\n",
    "\n",
    "    Returns:\n",
    "        A geodataframe with survey and topographical or color information extracted.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of all the filenames and path\n",
    "    list_files = filter_filename_list(\n",
    "        getListOfFiles(dataset_folder), fmt=[\".tif\", \".tiff\"]\n",
    "    )\n",
    "\n",
    "    dates = [getDate(dsm_in) for dsm_in in list_files]\n",
    "\n",
    "    # List all the transects datasets\n",
    "    if os.path.isdir(transect_folder):\n",
    "        list_trans = getListOfFiles(transect_folder)\n",
    "    elif os.path.isfile(transect_folder):\n",
    "        list_trans = getListOfFiles(transect_folder)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Set the sampling distance (step) for your profiles\n",
    "\n",
    "    gdf = pd.DataFrame()\n",
    "    counter = 0\n",
    "\n",
    "    if bool(add_slope):\n",
    "        warnings.warn(\n",
    "            \"WARNING: add_terrain could increas processing time considerably for fine scale DSMs.\"\n",
    "        )\n",
    "\n",
    "    for dsm in tqdm(list_files):\n",
    "        with ras.open(dsm, 'r') as ds:\n",
    "            nan_values = ds.nodata\n",
    "            print(nan_values)\n",
    "            if nan_values:\n",
    "                print(f\"found nan values = {nan_values}\")\n",
    "                pass\n",
    "            else:\n",
    "                nan_values=default_nan_values\n",
    "                print(nan_values)\n",
    "\n",
    "        date_string = getDate(dsm)\n",
    "        location = getLoc(dsm, list_loc_codes)\n",
    "\n",
    "\n",
    "        if bool(add_slope):\n",
    "\n",
    "            terr = rd.LoadGDAL(dsm, no_data=nan_values)\n",
    "            print(\n",
    "                f\"Computing slope DSM in degrees in {location} at date: {date_string} . . .\"\n",
    "            )\n",
    "            slope = rd.TerrainAttribute(terr, attrib=\"slope_degrees\")\n",
    "        else:\n",
    "            slope = False\n",
    "\n",
    "        transect_file_input = [a for a in list_trans if location in a]\n",
    "        transect_file = gpd.read_file(transect_file_input[0])\n",
    "\n",
    "        tr_list = np.arange(0, transect_file.shape[0])\n",
    "        for i in tqdm(tr_list):\n",
    "            if mode == \"dsm\":\n",
    "                temp = get_profiles(\n",
    "                    dsm,\n",
    "                    transect_file,\n",
    "                    i,\n",
    "                    sampling_step,\n",
    "                    location,\n",
    "                    date_string=date_string,\n",
    "                    add_xy=add_xy,\n",
    "                    add_terrain=slope,\n",
    "                )\n",
    "            elif mode == \"ortho\":\n",
    "                temp = get_profile_dn(\n",
    "                    dsm,\n",
    "                    transect_file,\n",
    "                    i,\n",
    "                    sampling_step,\n",
    "                    location,\n",
    "                    date_string=date_string,\n",
    "                    add_xy=add_xy,\n",
    "                )\n",
    "\n",
    "            gdf = pd.concat([temp, gdf], ignore_index=True)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    if counter == len(list_files):\n",
    "        print(\"Extraction succesfull\")\n",
    "    else:\n",
    "        print(f\"There is something wrong with this dataset: {list_files[counter]}\")\n",
    "\n",
    "    end = time.time()\n",
    "    timepassed = end - start\n",
    "\n",
    "    print(\n",
    "        f\"Number of points extracted:{gdf.shape[0]}\\nTime for processing={timepassed} seconds\\nFirst 10 rows are printed below\"\n",
    "    )\n",
    "\n",
    "    if mode == \"dsm\":\n",
    "        nan_out = np.count_nonzero(np.isnan(np.array(gdf.z).astype(\"f\")))\n",
    "        nan_raster = np.count_nonzero(gdf.z == nan_values)\n",
    "        gdf.z.replace(-10000, np.nan, inplace=True)\n",
    "\n",
    "    elif mode == \"ortho\":\n",
    "        nan_out = np.count_nonzero(\n",
    "            np.isnan(np.array(gdf[[\"band1\", \"band2\", \"band3\"]]).astype(\"f\"))\n",
    "        )\n",
    "        nan_raster = np.count_nonzero(gdf.band1 == nan_values)\n",
    "        gdf.band1.replace(0.0, np.nan, inplace=True)\n",
    "        gdf.band2.replace(0.0, np.nan, inplace=True)\n",
    "        gdf.band3.replace(0.0, np.nan, inplace=True)\n",
    "\n",
    "    print(\n",
    "        f\"Number of points outside the raster extents: {nan_out}\\nThe extraction assigns NaN.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Number of points in NoData areas within the raster extents: {nan_raster}\\nThe extraction assigns NaN.\"\n",
    "    )\n",
    "\n",
    "    return gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3454045951954d649b1c9b7db15c2a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf15bd375bfb4737b0ad43475d988e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f2575dd7ea418bbec36ebf8a992dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0970a6842ad413d8b35a82ad81cb1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc9fef9e7df4667b8b977ddb49e5519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cb01f8057a4fe3b0df86891f3e25f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248b31f8ec4443749e313aa6b5eb6ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f341cd52b68c425a98e5d3736db00909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed3a324d1cb4e639541de1c2df577ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeb3e18f3034a0498e51b8d32913bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a020895a38664b808cd6f93fc403827d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db9e396f14c4e76a3fd27c5f1d1780d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ae444250074be4826f669b47ba4a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafe96d4025f45698b44c40d37e3c33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b933ef77152454daf7fae5ade77114f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "-10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3422ffdbae461680de39e98e2614a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction succesfull\n",
      "Number of points extracted:32805\n",
      "Time for processing=42.2151153087616 seconds\n",
      "First 10 rows are printed below\n",
      "Number of points outside the raster extents: 27198\n",
      "The extraction assigns NaN.\n",
      "Number of points in NoData areas within the raster extents: 0\n",
      "The extraction assigns NaN.\n"
     ]
    }
   ],
   "source": [
    "gdf_rgb=extract_from_folder(dataset_folder=path_to_ortho,\n",
    "                        transect_folder=transect_folder,\n",
    "                        mode=\"ortho\",sampling_step=1,\n",
    "                        list_loc_codes=loc_codes,\n",
    "                        add_xy=True, \n",
    "                           add_slope = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\my_packages\\\\sandpyper\\\\tests\\\\test_data\\\\transects'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('tests/test_data/transects')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
