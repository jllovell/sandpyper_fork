{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225cff23",
   "metadata": {},
   "source": [
    "# Example 3 - Labels correction and multitemporal table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-indonesian",
   "metadata": {},
   "source": [
    "<img src=\"images/banner3.png\" width=\"100%\" />\n",
    "\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Sand classification, beachface clipping and multitemporal analysis</b></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Nicolas Pucino; PhD Student @ Deakin University, Australia </b> <br>\n",
    "<img style=\"padding:7px;\" src=\"images/sandpiper_sand_retouched.png\" width=\"170\" align=\"right\" /></font>\n",
    "\n",
    "<font size=\"3\">This notebook illustrates how to use assign the final Sand or no-sand labels to the points, clip only beachface areas and create an organised dataframe storing elevation changes from each period available in all locations. <br>\n",
    "\n",
    "<b>This notebook covers the following concepts:</b>\n",
    "\n",
    "- Sand vs No-Sand classification.\n",
    "- Beachface clipping.\n",
    "- Multitemporal extraction\n",
    "</font>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "satisfied-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sandpyper.outils import coords_to_points\n",
    "import os\n",
    "\n",
    "crs_dict_string= {\n",
    "                 'mar': {'init': 'epsg:32754'},\n",
    "                 'leo':{'init': 'epsg:32755'}\n",
    "                 }\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def check_dicts_duplicated_values(l_dicts):\n",
    "    \n",
    "    dict_check = {}\n",
    "    dict_dups = {}\n",
    "    all_dicts=[dicto for dicto in l_dicts.values()]\n",
    "\n",
    "    for dict_in in all_dicts:\n",
    "        for key in set().union(*all_dicts):\n",
    "            if key in dict_in:\n",
    "                dict_check.setdefault(key, []).extend(dict_in[key])\n",
    "\n",
    "    for survey, labels in dict_check.items():\n",
    "        duplicated=[x for x in labels if labels.count(x) > 1]\n",
    "        if len(duplicated)>=1:\n",
    "            dict_dups.update({survey:set(set(duplicated))})\n",
    "\n",
    "    if len(dict_dups)>0:\n",
    "        raise ValueError(f\"Duplicated label_k found in the following dictionaries.\\n\\n{dict_dups}\\n\\nPlease revise and assigned those labels_k to only one class dictionary.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "def classify_labelk(labelled_dataset,l_dicts, cluster_field='label_k', fill_class='sand'):\n",
    "\n",
    "    check_dicts_duplicated_values(l_dicts)\n",
    "    \n",
    "    labelled_dataset[\"pt_class\"]=np.nan\n",
    "\n",
    "\n",
    "    all_keys = set().union(*(d.keys() for d in [i for i in l_dicts.values()]))\n",
    "    class_names=l_dicts.keys()\n",
    "\n",
    "    classed_df=pd.DataFrame()\n",
    "\n",
    "    for loc in labelled_dataset.location.unique():\n",
    "        data_in_loc=labelled_dataset.query(f\"location=='{loc}'\")[[\"location\",\"raw_date\",cluster_field,\"pt_class\",'point_id']]\n",
    "\n",
    "        for raw_date in data_in_loc.raw_date.unique():\n",
    "            loc_date_tag=f\"{loc}_{raw_date}\"\n",
    "            data_in=data_in_loc.query(f\"raw_date=={raw_date}\")\n",
    "\n",
    "            if loc_date_tag in all_keys:\n",
    "\n",
    "                for class_in in class_names:\n",
    "\n",
    "                    if loc_date_tag in l_dicts[class_in].keys():\n",
    "                        loc_date_class_values=l_dicts[class_in][loc_date_tag]\n",
    "\n",
    "                        if len(loc_date_class_values)>=1:\n",
    "                            tmp_dict={label_k:class_in for label_k in loc_date_class_values}\n",
    "                            data_in['pt_class'].update(data_in[cluster_field].map(tmp_dict))\n",
    "\n",
    "                        else:\n",
    "                            pass\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                print(f\"{loc_date_tag} not in the class dictionaries. All their labels assigned to fill_class {fill_class}.\")\n",
    "                data_in[\"pt_class\"].fillna(fill_class, inplace=True)\n",
    "\n",
    "            classed_df=pd.concat([classed_df,data_in], ignore_index=True)\n",
    "\n",
    "    merged=pd.merge(left=labelled_dataset.iloc[:,:-1], right=classed_df[['point_id','pt_class']], on='point_id', how='left')\n",
    "    merged[\"pt_class\"].fillna(fill_class, inplace=True)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def cleanit(to_clean, l_dicts, cluster_field='label_k', fill_class='sand',\n",
    "            watermasks_path=None, water_label='water',\n",
    "            shoremasks_path=None, label_corrections_path=None,\n",
    "            default_crs={'init': 'epsg:32754'}, crs_dict_string=None,\n",
    "           geometry_field='coordinates'):\n",
    "    \n",
    "    print(\"Reclassifying dataset with the provided dictionaries.\" )\n",
    "    to_clean_classified=classify_labelk(to_clean, l_dicts)\n",
    "        \n",
    "    if watermasks_path==None and shoremasks_path==None and label_corrections_path==None:\n",
    "        print(\"No cleaning polygones have been passed. Returning classified dataset.\")\n",
    "        return to_clean_classified\n",
    "    \n",
    "    processes=[]\n",
    "        \n",
    "    if isinstance(to_clean_classified, pd.DataFrame):\n",
    "        print(f\"Pandas DataFrame provided. Transforming into GeoDataFrame with default_crs ({default_crs}) and provided field {geometry_field} .\")\n",
    "        \n",
    "        input_crs=default_crs\n",
    "        to_clean_classified.loc[:,'geometry']=to_clean_classified.loc[:,geometry_field].apply(coords_to_points)\n",
    "        to_clean_classified=gpd.GeoDataFrame(to_clean_classified, geometry='geometry', crs=input_crs)\n",
    "\n",
    "\n",
    "    elif isinstance(to_clean_classified, gpd.GeoDataFrame):\n",
    "        input_crs=to_clean_classified.crs\n",
    "    else:\n",
    "        raise ValueError(\"to_clean_classified must be either a GeoDataFrame or a DataFRame with a geometry column in string dtype.\")\n",
    "\n",
    "    \n",
    "    if label_corrections_path != None and os.path.isfile(label_corrections_path):\n",
    "        label_corrections=gpd.read_file(label_corrections_path)\n",
    "        print(f\"Label corrections provided in CRS: {label_corrections.crs}\")\n",
    "        processes.append(\"polygon finetuning\")\n",
    "        to_update_finetune=pd.DataFrame()\n",
    "        \n",
    "                \n",
    "        for loc in label_corrections.location.unique():\n",
    "            print(f\"Fine tuning in {loc}.\")\n",
    "            \n",
    "            to_clean_subset_loc=to_clean_classified.query(f\" location == '{loc}'\")\n",
    "            \n",
    "            for raw_date in tqdm(label_corrections.query(f\"location=='{loc}'\").raw_date.unique()):\n",
    "                \n",
    "                subset_finetune_polys=label_corrections.query(f\"location=='{loc}' and raw_date=={raw_date}\")\n",
    "                \n",
    "                for i,row in subset_finetune_polys.iterrows(): # loops through all the polygones\n",
    "\n",
    "                    target_k=int(row['target_label_k'])\n",
    "                    new_class=row['new_class']\n",
    "                    \n",
    "                    if target_k != 999:\n",
    "\n",
    "                        data_in=to_clean_subset_loc.query(f\"raw_date == {raw_date} and label_k=={target_k}\")\n",
    "                        \n",
    "                        selection=data_in[data_in.geometry.intersects(row['geometry'])]\n",
    "                        selection[\"finetuned_label\"]=new_class\n",
    "\n",
    "                    elif target_k == 999:\n",
    "\n",
    "                        data_in=to_clean_subset_loc.query(f\"raw_date == {raw_date}\")\n",
    "                        selection=data_in[data_in.geometry.intersects(row['geometry'])]\n",
    "                        selection[\"finetuned_label\"]=new_class\n",
    "\n",
    "                    print(f\"Fine-tuning label_k {target_k} to {new_class} in {loc}-{raw_date}, found {selection.shape[0]} pts.\")\n",
    "                    to_update_finetune=pd.concat([selection,to_update_finetune], ignore_index=True)\n",
    "                \n",
    "        classed_df_finetuned=pd.merge(left=to_clean_classified, right=to_update_finetune.loc[:,['point_id','finetuned_label']], # Left Join \n",
    "                                     how='left', validate='one_to_one') \n",
    "        classed_df_finetuned.finetuned_label.fillna(classed_df_finetuned.pt_class, inplace=True) # Fill NaN with previous sand labels\n",
    "        classed_df_finetuned[\"geometry\"]=classed_df_finetuned.coordinates.apply(coords_to_points)\n",
    "        classed_df_finetuned=gpd.GeoDataFrame(classed_df_finetuned,geometry='geometry', crs=input_crs)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if shoremasks_path == None and watermasks_path == None:\n",
    "        print(f\"{processes} completed.\")\n",
    "        return classed_df_finetuned\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    if watermasks_path != None and os.path.isfile(watermasks_path):\n",
    "        # apply watermasks\n",
    "        watermask=gpd.read_file(watermasks_path)\n",
    "        print(f\"watermask  provided in CRS: {watermask.crs}\")\n",
    "\n",
    "        \n",
    "        print(\"Applying watermasks cleaning.\")\n",
    "        processes.append(\"watermasking\")\n",
    "        \n",
    "        if \"polygon finetuning\" in processes:\n",
    "            dataset_to_clean=classed_df_finetuned\n",
    "            starting_labels='finetuned_label'\n",
    "        else:\n",
    "            dataset_to_clean=to_clean_classified\n",
    "            starting_labels='pt_class'\n",
    "            \n",
    "        \n",
    "        to_update_watermasked=pd.DataFrame()\n",
    "\n",
    "        for loc in watermask.location.unique():\n",
    "            print(f\"Watermasking in {loc}.\")\n",
    "            \n",
    "            for raw_date in tqdm(watermask.query(f\"location=='{loc}'\").raw_date.unique()):\n",
    "\n",
    "                subset_data=dataset_to_clean.query(f\"location=='{loc}' and raw_date == {raw_date}\")\n",
    "                subset_data[\"geometry\"]=subset_data.coordinates.apply(coords_to_points) # might not be necessery\n",
    "                subset_gdf=gpd.GeoDataFrame(subset_data,geometry='geometry', crs=crs_dict_string[loc])\n",
    "\n",
    "                subset_masks=watermask.query(f\"location=='{loc}' and raw_date == {raw_date}\")\n",
    "\n",
    "                selection=subset_gdf[subset_gdf.geometry.intersects(subset_masks.to_crs(crs_dict_string[loc]).geometry.iloc[0])]\n",
    "                print(f\"Setting to {water_label} {selection.shape[0]} pts overlapping provided watermasks.\")\n",
    "                \n",
    "                selection[\"watermasked_label\"]=water_label\n",
    "\n",
    "                to_update_watermasked=pd.concat([selection,to_update_watermasked], ignore_index=True)\n",
    "\n",
    "        classed_df_watermasked=pd.merge(left=dataset_to_clean, right=to_update_watermasked.loc[:,['point_id','watermasked_label']], # Left Join \n",
    "                                     how='left', validate='one_to_one') \n",
    "        classed_df_watermasked.watermasked_label.fillna(classed_df_watermasked.loc[:,starting_labels], inplace=True) # Fill NaN with previous sand labels\n",
    "        classed_df_watermasked[\"geometry\"]=classed_df_watermasked.coordinates.apply(coords_to_points)\n",
    "        classed_df_watermasked=gpd.GeoDataFrame(classed_df_watermasked,geometry='geometry', crs=input_crs)\n",
    "        \n",
    "        if shoremasks_path == None:\n",
    "            print(f\"{processes} completed.\")\n",
    "            return classed_df_watermasked\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if shoremasks_path != None and os.path.isfile(shoremasks_path):\n",
    "        # apply shoremasks\n",
    "        shoremask=gpd.read_file(shoremasks_path)\n",
    "        print(f\"shoremask  provided in CRS: {shoremask.crs}\")\n",
    "        print(\"Applying shoremasks cleaning.\")\n",
    "        processes.append(\"shoremasking\")\n",
    "        \n",
    "        \n",
    "        if \"polygon finetuning\" in processes and \"watermasking\" not in processes:\n",
    "            dataset_to_clean=classed_df_finetuned\n",
    "            starting_labels='finetuned_label'\n",
    "        elif \"polygon finetuning\" not in processes and \"watermasking\" in processes:\n",
    "            dataset_to_clean=classed_df_watermasked\n",
    "            starting_labels='watermasked_label'\n",
    "        else:\n",
    "            dataset_to_clean=to_clean_classified\n",
    "            starting_labels='pt_class'\n",
    "        \n",
    "        inshore_cleaned=gpd.GeoDataFrame()\n",
    "        for loc in shoremask.location.unique():\n",
    "            print(f\"Shoremasking in {loc}.\")\n",
    "            \n",
    "            shore=shoremask.query(f\"location=='{loc}'\")\n",
    "            loc_selection=dataset_to_clean.query(f\"location=='{loc}'\")\n",
    "            in_shore=loc_selection[loc_selection.geometry.intersects(shore.to_crs(crs_dict_string[loc]).geometry.iloc[0])]\n",
    "            print(f\"Removing {loc_selection.shape[0] - in_shore.shape[0]} pts falling outside provided shore polygones.\")\n",
    "            inshore_cleaned=pd.concat([in_shore,inshore_cleaned], ignore_index=True)\n",
    "\n",
    "    print(f\"{processes} completed.\")\n",
    "    return inshore_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "revolutionary-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_dataset=pd.read_csv(r\"C:\\my_packages\\sandpyper\\tests\\test_data\\test_to_classify.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41a05d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'point_id', 'label_k', 'distance', 'z', 'tr_id',\n",
       "       'raw_date', 'coordinates', 'location', 'survey_date', 'x', 'y', 'band1',\n",
       "       'band2', 'band3', 'spatial_id', 'pt_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "european-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QGIS Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b158d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_dict={'leo_20180606':[0,9,10],\n",
    "'leo_20180713':[0,3,4,7],\n",
    "'leo_20180920':[0,2,6,7],\n",
    "'leo_20190211':[0,2,5],\n",
    "'leo_20190328':[2,4,5],\n",
    "'leo_20190731':[0,2,8,6],\n",
    "'mar_20180601':[1,6],\n",
    "'mar_20180621':[4,6],\n",
    "'mar_20180727':[0,5,9,10],\n",
    "'mar_20180925':[0],\n",
    "'mar_20181113':[1],\n",
    "'mar_20181211':[4],\n",
    "'mar_20190205':[],\n",
    "'mar_20190313':[],\n",
    "'mar_20190516':[4,7]}\n",
    "\n",
    "no_sand_dict={'leo_20180606':[5],\n",
    "'leo_20180713':[],\n",
    "'leo_20180920':[],\n",
    "'leo_20190211':[1],\n",
    "'leo_20190328':[],\n",
    "'leo_20190731':[1],\n",
    "'mar_20180601':[4,5],\n",
    "'mar_20180621':[3,5],\n",
    "'mar_20180727':[4,7],\n",
    "'mar_20180925':[1,6],\n",
    "'mar_20181113':[0],\n",
    "'mar_20181211':[0],\n",
    "'mar_20190205':[0,5],\n",
    "'mar_20190313':[4],\n",
    "'mar_20190516':[2,5]}\n",
    "\n",
    "veg_dict={'leo_20180606':[1,3,7,8],\n",
    "'leo_20180713':[1,5,9],\n",
    "'leo_20180920':[1,4,5],\n",
    "'leo_20190211':[4],\n",
    "'leo_20190328':[0,1,6],\n",
    "'leo_20190731':[3,7],\n",
    "'mar_20180601':[0,7],\n",
    "'mar_20180621':[1,7],\n",
    "'mar_20180727':[1,3],\n",
    "'mar_20180925':[4],\n",
    "'mar_20181113':[3],\n",
    "'mar_20181211':[2],\n",
    "'mar_20190205':[3],\n",
    "'mar_20190313':[1,5],\n",
    "'mar_20190516':[0]}\n",
    "\n",
    "sand_dict={'leo_20180606':[2,4,6],\n",
    "'leo_20180713':[2,6,8],\n",
    "'leo_20180920':[3],\n",
    "'leo_20190211':[3],\n",
    "'leo_20190328':[3],\n",
    "'leo_20190731':[4,5],\n",
    "'mar_20180601':[2,3],\n",
    "'mar_20180621':[0,2],\n",
    "'mar_20180727':[2,6,8],\n",
    "'mar_20180925':[2,3,5],\n",
    "'mar_20181113':[2,4],\n",
    "'mar_20181211':[3,1],\n",
    "'mar_20190205':[1,2,4],\n",
    "'mar_20190313':[0,2,3],\n",
    "'mar_20190516':[1,3,6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "132f36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_dicts={'no_sand': no_sand_dict,\n",
    "         'sand': sand_dict,\n",
    "        'water': water_dict,\n",
    "        'veg':veg_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e6c475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_corrections_path=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\label_corrections.gpkg\"\n",
    "watermasks_path=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\watermasks.gpkg\"\n",
    "shoremasks_path=r\"C:\\my_packages\\sandpyper\\tests\\test_data\\shoremasks.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b515098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclassifying dataset with the provided dictionaries.\n",
      "Pandas DataFrame provided. Transforming into GeoDataFrame with default_crs ({'init': 'epsg:32754'}) and provided field coordinates .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\conda3\\envs\\sandpyper_env\\lib\\site-packages\\geopandas\\geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoremask  provided in CRS: epsg:32754\n",
      "Applying shoremasks cleaning.\n",
      "Shoremasking in mar.\n",
      "Removing 3621 pts falling outside provided shore polygones.\n",
      "Shoremasking in leo.\n",
      "Removing 2358 pts falling outside provided shore polygones.\n",
      "['shoremasking'] completed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>point_id</th>\n",
       "      <th>label_k</th>\n",
       "      <th>distance</th>\n",
       "      <th>z</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>band1</th>\n",
       "      <th>band2</th>\n",
       "      <th>band3</th>\n",
       "      <th>spatial_id</th>\n",
       "      <th>pt_class</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0400o21665066708le106</td>\n",
       "      <td>8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.173529</td>\n",
       "      <td>46</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299891.3490051675 5773713.769093407)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299891.349005</td>\n",
       "      <td>5.773714e+06</td>\n",
       "      <td>105.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>l00e46o016</td>\n",
       "      <td>veg</td>\n",
       "      <td>POINT (299891.349 5773713.769)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0400o21666017508le106</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.494270</td>\n",
       "      <td>46</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299892.3427646156 5773713.880637836)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299892.342765</td>\n",
       "      <td>5.773714e+06</td>\n",
       "      <td>84.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>l00e46o017</td>\n",
       "      <td>veg</td>\n",
       "      <td>POINT (299892.343 5773713.881)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>0400o21667068308le106</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.086379</td>\n",
       "      <td>46</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299893.3365240637 5773713.992182263)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299893.336524</td>\n",
       "      <td>5.773714e+06</td>\n",
       "      <td>73.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>l00e46o018</td>\n",
       "      <td>veg</td>\n",
       "      <td>POINT (299893.337 5773713.992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>0400o21667019108le106</td>\n",
       "      <td>7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.528307</td>\n",
       "      <td>46</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299894.3302835117 5773714.103726692)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299894.330284</td>\n",
       "      <td>5.773714e+06</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>l00e46o019</td>\n",
       "      <td>veg</td>\n",
       "      <td>POINT (299894.330 5773714.104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>0400o21668050908le206</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.864518</td>\n",
       "      <td>46</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299895.3240429598 5773714.215271119)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299895.324043</td>\n",
       "      <td>5.773714e+06</td>\n",
       "      <td>96.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>l00e46o020</td>\n",
       "      <td>veg</td>\n",
       "      <td>POINT (299895.324 5773714.215)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               point_id  label_k  distance         z  tr_id  \\\n",
       "0          29  0400o21665066708le106        8      16.0  1.173529     46   \n",
       "1          30  0400o21666017508le106        1      17.0  1.494270     46   \n",
       "2          31  0400o21667068308le106        1      18.0  2.086379     46   \n",
       "3          32  0400o21667019108le106        7      19.0  2.528307     46   \n",
       "4          33  0400o21668050908le206        3      20.0  2.864518     46   \n",
       "\n",
       "   raw_date                                  coordinates location survey_date  \\\n",
       "0  20180606  POINT (299891.3490051675 5773713.769093407)      leo  2018-06-06   \n",
       "1  20180606  POINT (299892.3427646156 5773713.880637836)      leo  2018-06-06   \n",
       "2  20180606  POINT (299893.3365240637 5773713.992182263)      leo  2018-06-06   \n",
       "3  20180606  POINT (299894.3302835117 5773714.103726692)      leo  2018-06-06   \n",
       "4  20180606  POINT (299895.3240429598 5773714.215271119)      leo  2018-06-06   \n",
       "\n",
       "               x             y  band1  band2  band3  spatial_id pt_class  \\\n",
       "0  299891.349005  5.773714e+06  105.0  113.0  101.0  l00e46o016      veg   \n",
       "1  299892.342765  5.773714e+06   84.0   91.0   77.0  l00e46o017      veg   \n",
       "2  299893.336524  5.773714e+06   73.0   81.0   86.0  l00e46o018      veg   \n",
       "3  299894.330284  5.773714e+06   51.0   58.0   66.0  l00e46o019      veg   \n",
       "4  299895.324043  5.773714e+06   96.0  102.0  107.0  l00e46o020      veg   \n",
       "\n",
       "                         geometry  \n",
       "0  POINT (299891.349 5773713.769)  \n",
       "1  POINT (299892.343 5773713.881)  \n",
       "2  POINT (299893.337 5773713.992)  \n",
       "3  POINT (299894.330 5773714.104)  \n",
       "4  POINT (299895.324 5773714.215)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshore_cleaned=cleanit(labelled_dataset, l_dicts, crs_dict_string=crs_dict_string,\n",
    "                        watermasks_path=None, \n",
    "                        shoremasks_path=shoremasks_path,\n",
    "                        label_corrections_path=None)\n",
    "\n",
    "inshore_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53605a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean_classified=classify_labelk(labelled_dataset, l_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ba8036b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>point_id</th>\n",
       "      <th>label_k</th>\n",
       "      <th>distance</th>\n",
       "      <th>z</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>band1</th>\n",
       "      <th>band2</th>\n",
       "      <th>band3</th>\n",
       "      <th>spatial_id</th>\n",
       "      <th>pt_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67144080l2610600eo00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.130296</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299873.2179654416 5773731.859571524)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299873.217965</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>133.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0le4o0700</td>\n",
       "      <td>veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>67148080l2690700eo10</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.085163</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299874.2117248897 5773731.971115951)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299874.211725</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>109.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0le4o0710</td>\n",
       "      <td>veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>67143080l2670800eo20</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.033864</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299875.2054843378 5773732.08266038)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299875.205484</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0le4o0720</td>\n",
       "      <td>veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>67148080l2650800eo30</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.025817</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299876.1992437858 5773732.194204807)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299876.199244</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>99.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0le4o0730</td>\n",
       "      <td>veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>67143080l2630900eo40</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.041824</td>\n",
       "      <td>47</td>\n",
       "      <td>20180606</td>\n",
       "      <td>POINT (299877.1930032339 5773732.305749236)</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>299877.193003</td>\n",
       "      <td>5.773732e+06</td>\n",
       "      <td>103.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0le4o0740</td>\n",
       "      <td>veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>23482</td>\n",
       "      <td>60102091m2535900ar70</td>\n",
       "      <td>5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9.786558</td>\n",
       "      <td>0</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731437.8933010239 5705159.623220895)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>731437.893301</td>\n",
       "      <td>5.705160e+06</td>\n",
       "      <td>92.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0ma0r0075</td>\n",
       "      <td>no_sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>23483</td>\n",
       "      <td>60109091m2566800ar70</td>\n",
       "      <td>5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>12.814320</td>\n",
       "      <td>0</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731436.8990619968 5705159.730406515)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>731436.899062</td>\n",
       "      <td>5.705160e+06</td>\n",
       "      <td>75.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0ma0r0076</td>\n",
       "      <td>no_sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>23484</td>\n",
       "      <td>60106091m2597800ar70</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>9.619781</td>\n",
       "      <td>0</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731435.9048229698 5705159.837592136)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>731435.904823</td>\n",
       "      <td>5.705160e+06</td>\n",
       "      <td>64.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0ma0r0077</td>\n",
       "      <td>veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>23485</td>\n",
       "      <td>60104091m2528800ar70</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.493135</td>\n",
       "      <td>0</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731434.9105839428 5705159.944777756)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>731434.910584</td>\n",
       "      <td>5.705160e+06</td>\n",
       "      <td>56.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0ma0r0078</td>\n",
       "      <td>veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23486</th>\n",
       "      <td>23486</td>\n",
       "      <td>60101091m2559700ar70</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>8.593991</td>\n",
       "      <td>0</td>\n",
       "      <td>20190516</td>\n",
       "      <td>POINT (731433.9163449157 5705160.051963376)</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>731433.916345</td>\n",
       "      <td>5.705160e+06</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0ma0r0079</td>\n",
       "      <td>veg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23487 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              point_id  label_k  distance          z  tr_id  \\\n",
       "0               0  67144080l2610600eo00        8       0.0   1.130296     47   \n",
       "1               1  67148080l2690700eo10        8       1.0   1.085163     47   \n",
       "2               2  67143080l2670800eo20        8       2.0   1.033864     47   \n",
       "3               3  67148080l2650800eo30        8       3.0   1.025817     47   \n",
       "4               4  67143080l2630900eo40        8       4.0   1.041824     47   \n",
       "...           ...                   ...      ...       ...        ...    ...   \n",
       "23482       23482  60102091m2535900ar70        5      75.0   9.786558      0   \n",
       "23483       23483  60109091m2566800ar70        5      76.0  12.814320      0   \n",
       "23484       23484  60106091m2597800ar70        0      77.0   9.619781      0   \n",
       "23485       23485  60104091m2528800ar70        0      78.0   8.493135      0   \n",
       "23486       23486  60101091m2559700ar70        0      79.0   8.593991      0   \n",
       "\n",
       "       raw_date                                  coordinates location  \\\n",
       "0      20180606  POINT (299873.2179654416 5773731.859571524)      leo   \n",
       "1      20180606  POINT (299874.2117248897 5773731.971115951)      leo   \n",
       "2      20180606   POINT (299875.2054843378 5773732.08266038)      leo   \n",
       "3      20180606  POINT (299876.1992437858 5773732.194204807)      leo   \n",
       "4      20180606  POINT (299877.1930032339 5773732.305749236)      leo   \n",
       "...         ...                                          ...      ...   \n",
       "23482  20190516  POINT (731437.8933010239 5705159.623220895)      mar   \n",
       "23483  20190516  POINT (731436.8990619968 5705159.730406515)      mar   \n",
       "23484  20190516  POINT (731435.9048229698 5705159.837592136)      mar   \n",
       "23485  20190516  POINT (731434.9105839428 5705159.944777756)      mar   \n",
       "23486  20190516  POINT (731433.9163449157 5705160.051963376)      mar   \n",
       "\n",
       "      survey_date              x             y  band1  band2  band3  \\\n",
       "0      2018-06-06  299873.217965  5.773732e+06  133.0  143.0  104.0   \n",
       "1      2018-06-06  299874.211725  5.773732e+06  109.0  107.0  106.0   \n",
       "2      2018-06-06  299875.205484  5.773732e+06   98.0   94.0  105.0   \n",
       "3      2018-06-06  299876.199244  5.773732e+06   99.0   97.0  108.0   \n",
       "4      2018-06-06  299877.193003  5.773732e+06  103.0  109.0  127.0   \n",
       "...           ...            ...           ...    ...    ...    ...   \n",
       "23482  2019-05-16  731437.893301  5.705160e+06   92.0  107.0   92.0   \n",
       "23483  2019-05-16  731436.899062  5.705160e+06   75.0   86.0   72.0   \n",
       "23484  2019-05-16  731435.904823  5.705160e+06   64.0   73.0   58.0   \n",
       "23485  2019-05-16  731434.910584  5.705160e+06   56.0   70.0   50.0   \n",
       "23486  2019-05-16  731433.916345  5.705160e+06   50.0   70.0   42.0   \n",
       "\n",
       "      spatial_id pt_class  \n",
       "0      0le4o0700      veg  \n",
       "1      0le4o0710      veg  \n",
       "2      0le4o0720      veg  \n",
       "3      0le4o0730      veg  \n",
       "4      0le4o0740      veg  \n",
       "...          ...      ...  \n",
       "23482  0ma0r0075  no_sand  \n",
       "23483  0ma0r0076  no_sand  \n",
       "23484  0ma0r0077      veg  \n",
       "23485  0ma0r0078      veg  \n",
       "23486  0ma0r0079      veg  \n",
       "\n",
       "[23487 rows x 17 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_clean_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4900817",
   "metadata": {},
   "outputs": [],
   "source": [
    "inshore_cleaned.to_csv(r\"C:\\my_packages\\sandpyper\\tests\\test_data\\test_cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
