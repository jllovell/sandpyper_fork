{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225cff23",
   "metadata": {},
   "source": [
    "# Example 3 - Labels correction and multitemporal table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-indonesian",
   "metadata": {},
   "source": [
    "<img src=\"images/banner3.png\" width=\"100%\" />\n",
    "\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Sand classification, beachface clipping and multitemporal analysis</b></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Nicolas Pucino; PhD Student @ Deakin University, Australia </b> <br>\n",
    "<img style=\"padding:7px;\" src=\"images/sandpiper_sand_retouched.png\" width=\"170\" align=\"right\" /></font>\n",
    "\n",
    "<font size=\"3\">This notebook illustrates how to use assign the final Sand or no-sand labels to the points, clip only beachface areas and create an organised dataframe storing elevation changes from each period available in all locations. <br>\n",
    "\n",
    "<b>This notebook covers the following concepts:</b>\n",
    "\n",
    "- Sand vs No-Sand classification.\n",
    "- Beachface clipping.\n",
    "- Multitemporal extraction\n",
    "</font>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satisfied-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "revolutionary-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_dataset=pd.read_csv(r\"C:\\my_packages\\doc_data\\labels\\data_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "european-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QGIS Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "infectious-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionaries and lists\n",
    "\n",
    "labels_dict={\"water\":0,\n",
    "            \"sand\":1,\n",
    "            \"vegetation\":2,\n",
    "            \"no_sand\":3}\n",
    "\n",
    "labels_sand=[1]\n",
    "labels_no_sand=[0,2,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "floppy-liberia",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "water_dict= {'mar_20180601': [],\n",
    " 'inv_20201020': [],\n",
    " 'inv_20200826': []}\n",
    "\n",
    "no_sand_dict={'inv_20201211': [7],\n",
    " 'inv_20201020': [],\n",
    " 'inv_20200826': []}\n",
    "\n",
    "veg_dict={'inv_20201211': [],\n",
    " 'inv_20201020': [],\n",
    " 'inv_20200826': []}\n",
    "\n",
    "sand_dict={'mar_20180601: [3,5,8,9],\n",
    " 'inv_20201020': [0,2,3,6,7,8],\n",
    " 'inv_20200826': [1,3,4,7,8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7216b21a",
   "metadata": {},
   "source": [
    "## Reclassification of sand labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "acceptable-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4225f520c354aa399200fabad5eee54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv.\n",
      "Working on: inv_20201211.\n",
      "inv_20201211, evaluating WATER.\n",
      "inv_20201211, evaluating SAND.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npucino\\AppData\\Local\\Continuum\\anaconda3\\envs\\transectenvi\\lib\\site-packages\\ipykernel\\__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_20201211, evaluating VEG.\n",
      "inv_20201211, evaluating NO_SAND.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npucino\\AppData\\Local\\Continuum\\anaconda3\\envs\\transectenvi\\lib\\site-packages\\ipykernel\\__main__.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In inv_20201211, the remaining labels [1, 4, 2, 6] are classified as no_sand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npucino\\AppData\\Local\\Continuum\\anaconda3\\envs\\transectenvi\\lib\\site-packages\\ipykernel\\__main__.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: inv_20201020.\n",
      "inv_20201020, evaluating WATER.\n",
      "inv_20201020, evaluating SAND.\n",
      "inv_20201020, evaluating VEG.\n",
      "inv_20201020, evaluating NO_SAND.\n",
      "In inv_20201020, the remaining labels [9, 5, 4, 1] are classified as no_sand.\n",
      "Working on: inv_20200826.\n",
      "inv_20200826, evaluating WATER.\n",
      "inv_20200826, evaluating SAND.\n",
      "inv_20200826, evaluating VEG.\n",
      "inv_20200826, evaluating NO_SAND.\n",
      "In inv_20200826, the remaining labels [6, 0, 9, 5, 2] are classified as no_sand.\n",
      "\n",
      "Checking for duplicated rows . . . \n",
      "Reclassification run successfully!\n",
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# classify sand VS no-sand\n",
    "\n",
    "df_labels=labelled_dataset\n",
    "\n",
    "corrected_labelled_df=pd.DataFrame()\n",
    "list_locs=labelled_dataset.location.unique()\n",
    "\n",
    "for location in tqdm(list_locs):\n",
    "    \n",
    "    print(f\"{location}.\")\n",
    "    \n",
    "    list_dates = df_labels.query(f\"location=='{location}'\").raw_date.unique()\n",
    "    \n",
    "    for survey_date in list_dates:\n",
    "                        \n",
    "        dataset_str=f\"{location}_{survey_date}\"\n",
    "        print(f\"Working on: {dataset_str}.\")\n",
    "        data_in=df_labels.query(f\"location=='{location}' & raw_date=='{survey_date}'\")\n",
    "        \n",
    "\n",
    "        list_labels=data_in.label_k.unique()   \n",
    "\n",
    "        # water\n",
    "        try:\n",
    "            print(f\"{dataset_str}, evaluating WATER.\")\n",
    "            label_df=data_in.query(f\"label_k == {water_dict[dataset_str]} \")\n",
    "            label_df[\"opt_label\"]=labels_dict[\"water\"]\n",
    "            corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "            list_labels=[e for e in list_labels if e not in water_dict[dataset_str]]\n",
    "        \n",
    "        except:\n",
    "            print(f\"{dataset_str} does not have water classes\")\n",
    "\n",
    "        # sand\n",
    "        try:\n",
    "            print(f\"{dataset_str}, evaluating SAND.\")\n",
    "            label_df=data_in.query(f\"label_k == {sand_dict[dataset_str]} \")\n",
    "            label_df[\"opt_label\"]=labels_dict[\"sand\"]\n",
    "            corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "            list_labels=[e for e in list_labels if e not in sand_dict[dataset_str]]\n",
    "\n",
    "        except:\n",
    "            print(f\"{dataset_str} does not have sand classes\")\n",
    "\n",
    "        # veg\n",
    "        try:\n",
    "            print(f\"{dataset_str}, evaluating VEG.\")\n",
    "            label_df=data_in.query(f\"label_k == {veg_dict[dataset_str]} \")\n",
    "            label_df[\"opt_label\"]=labels_dict[\"vegetation\"]\n",
    "            corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "            list_labels=[e for e in list_labels if e not in veg_dict[dataset_str]]\n",
    "            \n",
    "        except:\n",
    "            print(f\"{dataset_str} does not have vegetation classes\")\n",
    "\n",
    "        # no_sand\n",
    "        try:\n",
    "            print(f\"{dataset_str}, evaluating NO_SAND.\")\n",
    "            label_df=data_in.query(f\"label_k == {no_sand_dict[dataset_str]} \")\n",
    "            label_df[\"opt_label\"]=labels_dict[\"no_sand\"]\n",
    "            corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "            list_labels=[e for e in list_labels if e not in no_sand_dict[dataset_str]]\n",
    "        except:\n",
    "            print(f\"{dataset_str} does not have no_sand classes\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        print(f\"In {dataset_str}, the remaining labels {list_labels} are classified as no_sand.\")\n",
    "            \n",
    "        label_df=data_in.query(f\"label_k == {list_labels} \")\n",
    "        label_df[\"opt_label\"]=labels_dict[\"no_sand\"]            \n",
    "        corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "\n",
    "print(\"Checking for duplicated rows . . . \")\n",
    "\n",
    "if corrected_labelled_df.point_id.is_unique == False:\n",
    "    \n",
    "    print(\"There are some duplicated labels in the dictioanries. Run \"'duplicated_df.groupby(by=[\"location\",\"survey_date\",\"label_k\"]).count()'\" to find out. PLease correct them and re-run the cell. \")\n",
    "    # Select duplicate rows \n",
    "    duplicated_df = corrected_labelled_df[corrected_labelled_df.duplicated(['point_id'])]\n",
    "    duplicated_df.groupby(by=[\"location\",\"survey_date\",\"label_k\"]).count()\n",
    "else:\n",
    "    \n",
    "    print(\"Reclassification run successfully!\")\n",
    "\n",
    "\n",
    "corrected_labelled_df['sand_label'] = [ 1 if s in labels_no_sand else 0 for s in corrected_labelled_df.opt_label.values]\n",
    "corrected_labelled_df.sand_label.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "medieval-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>z</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>point_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "      <th>band1</th>\n",
       "      <th>band2</th>\n",
       "      <th>band3</th>\n",
       "      <th>slope</th>\n",
       "      <th>curve</th>\n",
       "      <th>label_k</th>\n",
       "      <th>opt_label</th>\n",
       "      <th>sand_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.416860</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389485.0292927367 5722796.792901353)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22837030600in006</td>\n",
       "      <td>389485.0292927367</td>\n",
       "      <td>5722796.792901353</td>\n",
       "      <td>POINT (389485.029 5722796.793)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-2.766547</td>\n",
       "      <td>1.376038</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.419285</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389485.0122613082 5722796.891440332)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22832000810in006</td>\n",
       "      <td>389485.0122613082</td>\n",
       "      <td>5722796.891440332</td>\n",
       "      <td>POINT (389485.012 5722796.891)</td>\n",
       "      <td>93.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-0.002408</td>\n",
       "      <td>1.382086</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.421676</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389484.9952298797 5722796.989979312)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22837070920in006</td>\n",
       "      <td>389484.9952298797</td>\n",
       "      <td>5722796.989979312</td>\n",
       "      <td>POINT (389484.995 5722796.990)</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-0.002375</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.424035</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389484.9781984512 5722797.088518291)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22832050130in006</td>\n",
       "      <td>389484.97819845116</td>\n",
       "      <td>5722797.088518291</td>\n",
       "      <td>POINT (389484.978 5722797.089)</td>\n",
       "      <td>85.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-0.002343</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.426361</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389484.9611670226 5722797.18705727)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22836020240in006</td>\n",
       "      <td>389484.96116702264</td>\n",
       "      <td>5722797.18705727</td>\n",
       "      <td>POINT (389484.961 5722797.187)</td>\n",
       "      <td>88.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-0.003679</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320347</td>\n",
       "      <td>92.5</td>\n",
       "      <td>3.377417</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.7613396471 5721639.905428521)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10204001i2272101nv95</td>\n",
       "      <td>386871.7613396471</td>\n",
       "      <td>5721639.905428521</td>\n",
       "      <td>POINT (386871.761 5721639.905)</td>\n",
       "      <td>97.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320348</td>\n",
       "      <td>92.6</td>\n",
       "      <td>3.402572</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.7460518774 5721640.004253033)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10207001i2272401nv96</td>\n",
       "      <td>386871.7460518774</td>\n",
       "      <td>5721640.004253033</td>\n",
       "      <td>POINT (386871.746 5721640.004)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>-0.006844</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320349</td>\n",
       "      <td>92.7</td>\n",
       "      <td>3.402572</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.7307641076 5721640.103077544)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10200001i2272601nv97</td>\n",
       "      <td>386871.7307641076</td>\n",
       "      <td>5721640.103077544</td>\n",
       "      <td>POINT (386871.731 5721640.103)</td>\n",
       "      <td>101.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.006841</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320350</td>\n",
       "      <td>92.8</td>\n",
       "      <td>3.400400</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.7154763379 5721640.201902056)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10203001i2272901nv98</td>\n",
       "      <td>386871.7154763379</td>\n",
       "      <td>5721640.201902056</td>\n",
       "      <td>POINT (386871.715 5721640.202)</td>\n",
       "      <td>103.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>-0.006097</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320351</td>\n",
       "      <td>93.3</td>\n",
       "      <td>3.373779</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.6390374891 5721640.696024614)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10208001i2293101nv93</td>\n",
       "      <td>386871.6390374891</td>\n",
       "      <td>5721640.696024614</td>\n",
       "      <td>POINT (386871.639 5721640.696)</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-0.012963</td>\n",
       "      <td>-0.007356</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320352 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance         z tr_id  raw_date  \\\n",
       "0            0.0 -0.416860   163  20200826   \n",
       "1            0.1 -0.419285   163  20200826   \n",
       "2            0.2 -0.421676   163  20200826   \n",
       "3            0.3 -0.424035   163  20200826   \n",
       "4            0.4 -0.426361   163  20200826   \n",
       "...          ...       ...   ...       ...   \n",
       "320347      92.5  3.377417     0  20201211   \n",
       "320348      92.6  3.402572     0  20201211   \n",
       "320349      92.7  3.402572     0  20201211   \n",
       "320350      92.8  3.400400     0  20201211   \n",
       "320351      93.3  3.373779     0  20201211   \n",
       "\n",
       "                                        coordinates location survey_date  \\\n",
       "0       POINT (389485.0292927367 5722796.792901353)      inv  2020-08-26   \n",
       "1       POINT (389485.0122613082 5722796.891440332)      inv  2020-08-26   \n",
       "2       POINT (389484.9952298797 5722796.989979312)      inv  2020-08-26   \n",
       "3       POINT (389484.9781984512 5722797.088518291)      inv  2020-08-26   \n",
       "4        POINT (389484.9611670226 5722797.18705727)      inv  2020-08-26   \n",
       "...                                             ...      ...         ...   \n",
       "320347  POINT (386871.7613396471 5721639.905428521)      inv  2020-12-11   \n",
       "320348  POINT (386871.7460518774 5721640.004253033)      inv  2020-12-11   \n",
       "320349  POINT (386871.7307641076 5721640.103077544)      inv  2020-12-11   \n",
       "320350  POINT (386871.7154763379 5721640.201902056)      inv  2020-12-11   \n",
       "320351  POINT (386871.6390374891 5721640.696024614)      inv  2020-12-11   \n",
       "\n",
       "                     point_id                   x                  y  \\\n",
       "0       2601v22837030600in006   389485.0292927367  5722796.792901353   \n",
       "1       2601v22832000810in006   389485.0122613082  5722796.891440332   \n",
       "2       2601v22837070920in006   389484.9952298797  5722796.989979312   \n",
       "3       2601v22832050130in006  389484.97819845116  5722797.088518291   \n",
       "4       2601v22836020240in006  389484.96116702264   5722797.18705727   \n",
       "...                       ...                 ...                ...   \n",
       "320347   10204001i2272101nv95   386871.7613396471  5721639.905428521   \n",
       "320348   10207001i2272401nv96   386871.7460518774  5721640.004253033   \n",
       "320349   10200001i2272601nv97   386871.7307641076  5721640.103077544   \n",
       "320350   10203001i2272901nv98   386871.7154763379  5721640.201902056   \n",
       "320351   10208001i2293101nv93   386871.6390374891  5721640.696024614   \n",
       "\n",
       "                              geometry  band1  band2 band3     slope  \\\n",
       "0       POINT (389485.029 5722796.793)   94.0   91.0  95.0 -2.766547   \n",
       "1       POINT (389485.012 5722796.891)   93.0   89.0  93.0 -0.002408   \n",
       "2       POINT (389484.995 5722796.990)   89.0   85.0  89.0 -0.002375   \n",
       "3       POINT (389484.978 5722797.089)   85.0   83.0  86.0 -0.002343   \n",
       "4       POINT (389484.961 5722797.187)   88.0   85.0  91.0 -0.003679   \n",
       "...                                ...    ...    ...   ...       ...   \n",
       "320347  POINT (386871.761 5721639.905)   97.0  116.0  70.0  0.012603   \n",
       "320348  POINT (386871.746 5721640.004)   86.0  112.0  61.0  0.012578   \n",
       "320349  POINT (386871.731 5721640.103)  101.0  128.0  76.0 -0.001086   \n",
       "320350  POINT (386871.715 5721640.202)  103.0  127.0  76.0 -0.001105   \n",
       "320351  POINT (386871.639 5721640.696)  103.0  112.0  87.0 -0.012963   \n",
       "\n",
       "           curve  label_k  opt_label  sand_label  \n",
       "0       1.376038        6          3           1  \n",
       "1       1.382086        6          3           1  \n",
       "2       0.000033        0          3           1  \n",
       "3      -0.000652        0          3           1  \n",
       "4      -0.000640        0          3           1  \n",
       "...          ...      ...        ...         ...  \n",
       "320347  0.006434        9          1           0  \n",
       "320348 -0.006844        9          1           0  \n",
       "320349 -0.006841        9          1           0  \n",
       "320350 -0.006097        9          1           0  \n",
       "320351 -0.007356        9          1           0  \n",
       "\n",
       "[320352 rows x 19 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a geodataframe with point objects\n",
    "\n",
    "corrected_labelled_df = corrected_labelled_df.loc[:,~corrected_labelled_df.columns.duplicated()] # eliminate duplicated columns\n",
    "corrected_labelled_df['geometry']=corrected_labelled_df.coordinates.apply(coords_to_points) # create Point objects\n",
    "corrected_labelled_gdf=gpd.GeoDataFrame(corrected_labelled_df, geometry='geometry', crs=crs_dict_string['inv']) # create GeoDataFrame\n",
    "corrected_labelled_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04568038",
   "metadata": {},
   "source": [
    "## Polygon correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "appropriate-threshold",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_Not_Sand.gpkg: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_Not_Sand.gpkg: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\conda3\\envs\\sandpiper_env\\lib\\site-packages\\geopandas\\io\\file.py\u001b[0m in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda3\\envs\\sandpiper_env\\lib\\site-packages\\fiona\\env.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda3\\envs\\sandpiper_env\\lib\\site-packages\\fiona\\__init__.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[1;32m--> 257\u001b[1;33m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda3\\envs\\sandpiper_env\\lib\\site-packages\\fiona\\collection.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_Not_Sand.gpkg: No such file or directory"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# apply poly correction with geopandas\n",
    "\n",
    "#labelled_gdf=corrected_labelled_gdf\n",
    "corr_date_field='survey_date'\n",
    "labelled_df_date_field='raw_date'\n",
    "\n",
    "is_sand_path=r\"E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_ToSand.gpkg\"\n",
    "is_not_sand_path=r\"E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_Not_Sand.gpkg\"\n",
    "shore_path=r\"C:\\jupyter\\shore_areas\\inv_shore.gpkg\"\n",
    "\n",
    "#____________\n",
    "chloe_vali_noSand=gpd.read_file(is_not_sand_path)\n",
    "\n",
    "if '-' in chloe_vali_noSand.loc[:,corr_date_field].any():\n",
    "    chloe_vali_noSand.loc[:,corr_date_field]=chloe_vali_noSand.loc[:,corr_date_field].apply(lambda x: x.replace('-',''))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if corr_date_field != 'date_raw':\n",
    "    chloe_vali_noSand.rename({corr_date_field:'date_raw'}, axis=1, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "chloe_vali_Sand=gpd.read_file(is_sand_path)\n",
    "\n",
    "if '-' in chloe_vali_Sand.loc[:,corr_date_field].any():\n",
    "    chloe_vali_Sand.loc[:,corr_date_field]=chloe_vali_Sand.loc[:,corr_date_field].apply(lambda x: x.replace('-',''))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if corr_date_field != 'date_raw':\n",
    "    chloe_vali_Sand.rename({corr_date_field:'date_raw'}, axis=1, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "# check wether the correction geopackages are empty or not. If empty, skip correction.\n",
    "if chloe_vali_Sand.empty:\n",
    "    skip_isSand=True\n",
    "    print(\"Correction TO SAND skipped as the provided file is empty.\")\n",
    "else:\n",
    "    skip_isSand=False\n",
    "    \n",
    "if chloe_vali_noSand.empty:\n",
    "    skip_NoSand=True\n",
    "    print(\"Correction TO NO-SAND skipped as the provided file is empty.\")\n",
    "else:\n",
    "    skip_NoSand=False\n",
    "    \n",
    "\n",
    "# Poly correction starts here______________________________________\n",
    "\n",
    "to_update=pd.DataFrame()\n",
    "\n",
    "for date_in in labelled_gdf.loc[:,labelled_df_date_field].unique():\n",
    "\n",
    "    #subset points and polygones based on date\n",
    "    data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}'\")\n",
    "    vali_isSand=chloe_vali_Sand.query(f\"date_raw == '{date_in}'\")\n",
    "    vali_NoSand=chloe_vali_noSand.query(f\"date_raw == '{date_in}'\")\n",
    "    \n",
    "    # first set what IS SAND\n",
    "    if bool(skip_isSand)==True or vali_isSand.empty:\n",
    "        pass\n",
    "    else:\n",
    "        for i in range(vali_isSand.shape[0]): # loops through all the polygones\n",
    "\n",
    "            target_k=int(vali_isSand.iloc[i]['target_label_k'])\n",
    "\n",
    "            if target_k != 999:\n",
    "\n",
    "                data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}' & label_k=='{target_k}'\")\n",
    "                selection=data_in[data_in.geometry.intersects(vali_isSand.geometry.iloc[i])]\n",
    "                selection[\"corr_label\"]=0\n",
    "\n",
    "            elif target_k == 999:\n",
    "\n",
    "                data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}'\")\n",
    "                selection=data_in[data_in.geometry.intersects(vali_isSand.geometry.iloc[i])]\n",
    "                selection[\"corr_label\"]=0\n",
    "\n",
    "        to_update=pd.concat([selection,to_update], ignore_index=True)\n",
    "        \n",
    "            \n",
    "    # Now set what IS NOT SAND\n",
    "    if skip_NoSand or vali_NoSand.empty:\n",
    "        pass\n",
    "    else:\n",
    "        for i in range(vali_NoSand.shape[0]): # loops through all the polygones\n",
    "\n",
    "            target_k=int(vali_NoSand.iloc[i]['target_label_k'])\n",
    "\n",
    "            if target_k != 999:\n",
    "\n",
    "                data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}' & label_k=='{target_k}'\")\n",
    "                selection=data_in[data_in.geometry.intersects(vali_NoSand.geometry.iloc[i])]\n",
    "                selection[\"corr_label\"]=1\n",
    "\n",
    "            elif target_k == 999:\n",
    "\n",
    "                data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}'\")\n",
    "                selection=data_in[data_in.geometry.intersects(vali_NoSand.geometry.iloc[i])]\n",
    "                selection[\"corr_label\"]=1\n",
    "\n",
    "        to_update=pd.concat([selection,to_update], ignore_index=True)\n",
    "    \n",
    "to_update.drop_duplicates(subset=\"point_id\", inplace=True)\n",
    "\n",
    "\n",
    "#__CREATE NEW UPDATED DATAFRAME____________________________\n",
    "labelled_df_updated=pd.merge(left=labelled_gdf, right=to_update.loc[:,['point_id','corr_label']], # Left Join \n",
    "                             how='left', validate='one_to_one') \n",
    "labelled_df_updated.corr_label.fillna(labelled_df_updated.sand_label, inplace=True) # Fill NaN with previous sand labels\n",
    "labelled_df_updated[\"corr_label\"]=labelled_df_updated.corr_label.astype(int) # Transform corr_labels in Int\n",
    "\n",
    "#__CLIP BY SHORE____________________________\n",
    "shore=gpd.read_file(shore_path)\n",
    "in_shore=labelled_df_updated[labelled_df_updated.geometry.intersects(shore.geometry.iloc[0])]\n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "in_shore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "novel-appeal",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_shore.to_csv(r\"E:\\chapter_4\\chloe_inv\\add3\\labels\\add3_inv_labelled_inshore.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd28f04",
   "metadata": {},
   "source": [
    "## Create multitemporal datased (dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "150b6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multitemporal Extraction to loop trough locations\n",
    "\n",
    "full_dataset=pd.read_csv(r\"C:\\my_packages\\doc_data\\profiles\\classified_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "constant-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multitemporal (df,\n",
    "                           filter_sand=True,\n",
    "                           date_field='survey_date',\n",
    "                          sand_label_field='label_sand',\n",
    "                           filter_classes=[0],\n",
    "                          common_field=\"geometry\"):\n",
    "    \"\"\"\n",
    "    From a dataframe containing the extracted points and a column specifying wether they are sand or non-sand, returns a multitemporal dataframe\n",
    "    with time-periods sand-specific elevation changes.\n",
    "\n",
    "    Args:\n",
    "        date_field (str): the name of the column storing the survey date.\n",
    "        sand_label_field (str): the name of the column storing the sand label (usually sand=0, no_sand=1).\n",
    "        filter_classes (list): list of integers specifiying the label numbers of the sand_label_field that are sand. Default [0].\n",
    "        common_field (str): name of the field where the points share the same name. It is usually the geometry or spatial IDs.\n",
    "\n",
    "    Returns:\n",
    "        A multitemporal dataframe of sand-specific elevation changes.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    fusion_long=pd.DataFrame()\n",
    "\n",
    "    for location in df.location.unique():\n",
    "        print(f\"working on {location}\")\n",
    "        loc_data=df.query(f\"location=='{location}'\")\n",
    "        list_dates=loc_data.loc[:,date_field].unique()\n",
    "        list_dates.sort()\n",
    "\n",
    "\n",
    "        for i in tqdm(range(list_dates.shape[0])):\n",
    "\n",
    "            if i < list_dates.shape[0]-1:\n",
    "                date_pre=list_dates[i]\n",
    "                date_post=list_dates[i+1]\n",
    "                print(f\"Calculating dt{i}, from {date_pre} to {date_post} in {location}.\")\n",
    "                \n",
    "                if filter_sand:\n",
    "                    df_pre=loc_data.query(f\"{date_field} =='{date_pre}' & {sand_label_field} in {filter_classes}\").dropna(subset=['z'])\n",
    "                    df_post=loc_data.query(f\"{date_field} =='{date_post}' & {sand_label_field} in {filter_classes}\").dropna(subset=['z'])\n",
    "                else:\n",
    "                    df_pre=loc_data.query(f\"{date_field} =='{date_pre}'\").dropna(subset=['z'])\n",
    "                    df_post=loc_data.query(f\"{date_field} =='{date_post}'\").dropna(subset=['z'])\n",
    "                \n",
    "                merged=pd.merge(df_pre,df_post, how='inner', on=common_field,validate=\"one_to_one\",suffixes=('_pre','_post'))\n",
    "                merged[\"dh\"]=merged.z_post.astype(float) - merged.z_pre.astype(float)\n",
    "\n",
    "                dict_short={\"geometry\": merged.geometry,\n",
    "                            \"location\":location,\n",
    "                            \"tr_id\":merged.tr_id_pre,\n",
    "                            \"distance\":merged.distance_pre,\n",
    "                            \"dt\":  f\"dt_{i}\",\n",
    "                            \"date_pre\":date_pre,\n",
    "                            \"date_post\":date_post,\n",
    "                            \"z_pre\":merged.z_pre.astype(float),\n",
    "                            \"z_post\":merged.z_post.astype(float),\n",
    "                            \"dh\":merged.dh}\n",
    "\n",
    "                short_df=pd.DataFrame(dict_short)\n",
    "                fusion_long=pd.concat([short_df,fusion_long],ignore_index=True)\n",
    "\n",
    "    print(\"done\")\n",
    "    return fusion_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfe31322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>point_id</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>z</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>label_sand</th>\n",
       "      <th>spatial_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62122091m2510340ar20</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>22ar0m24</td>\n",
       "      <td>POINT (731624.209562121 5705492.44046626)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62126091m2590390ar20</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>22ar0m29</td>\n",
       "      <td>POINT (731623.785562969 5705492.70546573)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64121091m2580400ar00</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>-0.004194</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24ar0m00</td>\n",
       "      <td>POINT (731646.903760184 5705523.4689886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64121091m2510250ar00</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>-0.004196</td>\n",
       "      <td>24</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>24ar0m05</td>\n",
       "      <td>POINT (731646.491030611 5705523.75121953)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>64128091m2520270ar00</td>\n",
       "      <td>mar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>-0.004196</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>24ar0m07</td>\n",
       "      <td>POINT (731646.325938782 5705523.8641119)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105032</th>\n",
       "      <td>34455</td>\n",
       "      <td>ol906089201e002306</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>1.429813</td>\n",
       "      <td>69</td>\n",
       "      <td>30.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0le6o6930</td>\n",
       "      <td>POINT (299898.0365287552 5773691.407968608)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105033</th>\n",
       "      <td>34456</td>\n",
       "      <td>ol92101208500300e</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>-0.244038</td>\n",
       "      <td>53</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>53eo0l01</td>\n",
       "      <td>POINT (300001.0901262025 5773392.246766388)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105034</th>\n",
       "      <td>34457</td>\n",
       "      <td>ol950820143e032010</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>1.162140</td>\n",
       "      <td>45</td>\n",
       "      <td>33.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0le4o1533</td>\n",
       "      <td>POINT (300031.9095018596 5773232.738285414)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105035</th>\n",
       "      <td>34458</td>\n",
       "      <td>ole120903080295600</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>5.996941</td>\n",
       "      <td>50</td>\n",
       "      <td>39.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0le5o6039</td>\n",
       "      <td>POINT (299987.0210992148 5773321.983921126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105036</th>\n",
       "      <td>34459</td>\n",
       "      <td>ole981020821010025</td>\n",
       "      <td>leo</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0.319957</td>\n",
       "      <td>51</td>\n",
       "      <td>21.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0le5o8121</td>\n",
       "      <td>POINT (299996.8454807236 5773346.928906675)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105037 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0              point_id location survey_date         z  \\\n",
       "0                0  62122091m2510340ar20      mar  2019-05-16       NaN   \n",
       "1                1  62126091m2590390ar20      mar  2019-05-16       NaN   \n",
       "2                2  64121091m2580400ar00      mar  2019-05-16 -0.004194   \n",
       "3                3  64121091m2510250ar00      mar  2019-05-16 -0.004196   \n",
       "4                4  64128091m2520270ar00      mar  2019-05-16 -0.004196   \n",
       "...            ...                   ...      ...         ...       ...   \n",
       "105032       34455    ol906089201e002306      leo  2018-09-20  1.429813   \n",
       "105033       34456     ol92101208500300e      leo  2018-09-20 -0.244038   \n",
       "105034       34457    ol950820143e032010      leo  2018-09-20  1.162140   \n",
       "105035       34458    ole120903080295600      leo  2018-09-20  5.996941   \n",
       "105036       34459    ole981020821010025      leo  2018-09-20  0.319957   \n",
       "\n",
       "        tr_id  distance  label_sand spatial_id  \\\n",
       "0          22       2.4           1   22ar0m24   \n",
       "1          22       2.9           1   22ar0m29   \n",
       "2          24       0.0           1   24ar0m00   \n",
       "3          24       0.5           1   24ar0m05   \n",
       "4          24       0.7           1   24ar0m07   \n",
       "...       ...       ...         ...        ...   \n",
       "105032     69      30.6           1  0le6o6930   \n",
       "105033     53       0.1           1   53eo0l01   \n",
       "105034     45      33.1           1  0le4o1533   \n",
       "105035     50      39.6           1  0le5o6039   \n",
       "105036     51      21.8           1  0le5o8121   \n",
       "\n",
       "                                           geometry  \n",
       "0         POINT (731624.209562121 5705492.44046626)  \n",
       "1         POINT (731623.785562969 5705492.70546573)  \n",
       "2          POINT (731646.903760184 5705523.4689886)  \n",
       "3         POINT (731646.491030611 5705523.75121953)  \n",
       "4          POINT (731646.325938782 5705523.8641119)  \n",
       "...                                             ...  \n",
       "105032  POINT (299898.0365287552 5773691.407968608)  \n",
       "105033  POINT (300001.0901262025 5773392.246766388)  \n",
       "105034  POINT (300031.9095018596 5773232.738285414)  \n",
       "105035  POINT (299987.0210992148 5773321.983921126)  \n",
       "105036  POINT (299996.8454807236 5773346.928906675)  \n",
       "\n",
       "[105037 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d31782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on mar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00101e095b24c518f016039c5afeced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dt0, from 2018-06-01 to 2018-06-21 in mar.\n",
      "Calculating dt1, from 2018-06-21 to 2018-07-27 in mar.\n",
      "Calculating dt2, from 2018-07-27 to 2018-09-25 in mar.\n",
      "Calculating dt3, from 2018-09-25 to 2018-11-13 in mar.\n",
      "Calculating dt4, from 2018-11-13 to 2018-12-11 in mar.\n",
      "Calculating dt5, from 2018-12-11 to 2019-02-05 in mar.\n",
      "Calculating dt6, from 2019-02-05 to 2019-03-13 in mar.\n",
      "Calculating dt7, from 2019-03-13 to 2019-05-16 in mar.\n",
      "working on leo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1690a0ced99459794f1eeda322c8f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dt0, from 2018-06-06 to 2018-07-13 in leo.\n",
      "Calculating dt1, from 2018-07-13 to 2018-07-25 in leo.\n",
      "Calculating dt2, from 2018-07-25 to 2018-09-20 in leo.\n",
      "Calculating dt3, from 2018-09-20 to 2019-02-11 in leo.\n",
      "Calculating dt4, from 2019-02-11 to 2019-03-28 in leo.\n",
      "Calculating dt5, from 2019-03-28 to 2019-07-31 in leo.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dh_df=compute_multitemporal(full_dataset,\n",
    "                      date_field='survey_date',\n",
    "                      sand_label_field='label_sand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8792df48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>location</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>dt</th>\n",
       "      <th>date_pre</th>\n",
       "      <th>date_post</th>\n",
       "      <th>z_pre</th>\n",
       "      <th>z_post</th>\n",
       "      <th>dh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (299901.7782793006 5773692.070767866)</td>\n",
       "      <td>leo</td>\n",
       "      <td>69</td>\n",
       "      <td>26.8</td>\n",
       "      <td>dt_5</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0.223866</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>-0.111029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (299901.4828779417 5773692.018441608)</td>\n",
       "      <td>leo</td>\n",
       "      <td>69</td>\n",
       "      <td>27.1</td>\n",
       "      <td>dt_5</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0.256890</td>\n",
       "      <td>0.152005</td>\n",
       "      <td>-0.104885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (299901.2859437025 5773691.983557437)</td>\n",
       "      <td>leo</td>\n",
       "      <td>69</td>\n",
       "      <td>27.3</td>\n",
       "      <td>dt_5</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.176710</td>\n",
       "      <td>-0.106624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (299901.1874765829 5773691.966115351)</td>\n",
       "      <td>leo</td>\n",
       "      <td>69</td>\n",
       "      <td>27.4</td>\n",
       "      <td>dt_5</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0.305573</td>\n",
       "      <td>0.188821</td>\n",
       "      <td>-0.116752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (299901.0890094633 5773691.948673265)</td>\n",
       "      <td>leo</td>\n",
       "      <td>69</td>\n",
       "      <td>27.5</td>\n",
       "      <td>dt_5</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0.329158</td>\n",
       "      <td>0.197999</td>\n",
       "      <td>-0.131160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38676</th>\n",
       "      <td>POINT (731460.3631030347 5705157.200825883)</td>\n",
       "      <td>mar</td>\n",
       "      <td>3</td>\n",
       "      <td>52.4</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>4.663569</td>\n",
       "      <td>4.665780</td>\n",
       "      <td>0.002210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38677</th>\n",
       "      <td>POINT (731460.263679132 5705157.211544445)</td>\n",
       "      <td>mar</td>\n",
       "      <td>3</td>\n",
       "      <td>52.5</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>4.780209</td>\n",
       "      <td>4.787802</td>\n",
       "      <td>0.007593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38678</th>\n",
       "      <td>POINT (731460.1642552292 5705157.222263007)</td>\n",
       "      <td>mar</td>\n",
       "      <td>3</td>\n",
       "      <td>52.6</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>4.875618</td>\n",
       "      <td>4.903659</td>\n",
       "      <td>0.028041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38679</th>\n",
       "      <td>POINT (731460.0648313265 5705157.232981569)</td>\n",
       "      <td>mar</td>\n",
       "      <td>3</td>\n",
       "      <td>52.7</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>4.970114</td>\n",
       "      <td>4.974202</td>\n",
       "      <td>0.004088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38680</th>\n",
       "      <td>POINT (731458.6728966887 5705157.383041437)</td>\n",
       "      <td>mar</td>\n",
       "      <td>3</td>\n",
       "      <td>54.1</td>\n",
       "      <td>dt_0</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>5.917675</td>\n",
       "      <td>5.955576</td>\n",
       "      <td>0.037901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38681 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          geometry location  tr_id  distance  \\\n",
       "0      POINT (299901.7782793006 5773692.070767866)      leo     69      26.8   \n",
       "1      POINT (299901.4828779417 5773692.018441608)      leo     69      27.1   \n",
       "2      POINT (299901.2859437025 5773691.983557437)      leo     69      27.3   \n",
       "3      POINT (299901.1874765829 5773691.966115351)      leo     69      27.4   \n",
       "4      POINT (299901.0890094633 5773691.948673265)      leo     69      27.5   \n",
       "...                                            ...      ...    ...       ...   \n",
       "38676  POINT (731460.3631030347 5705157.200825883)      mar      3      52.4   \n",
       "38677   POINT (731460.263679132 5705157.211544445)      mar      3      52.5   \n",
       "38678  POINT (731460.1642552292 5705157.222263007)      mar      3      52.6   \n",
       "38679  POINT (731460.0648313265 5705157.232981569)      mar      3      52.7   \n",
       "38680  POINT (731458.6728966887 5705157.383041437)      mar      3      54.1   \n",
       "\n",
       "         dt    date_pre   date_post     z_pre    z_post        dh  \n",
       "0      dt_5  2019-03-28  2019-07-31  0.223866  0.112838 -0.111029  \n",
       "1      dt_5  2019-03-28  2019-07-31  0.256890  0.152005 -0.104885  \n",
       "2      dt_5  2019-03-28  2019-07-31  0.283333  0.176710 -0.106624  \n",
       "3      dt_5  2019-03-28  2019-07-31  0.305573  0.188821 -0.116752  \n",
       "4      dt_5  2019-03-28  2019-07-31  0.329158  0.197999 -0.131160  \n",
       "...     ...         ...         ...       ...       ...       ...  \n",
       "38676  dt_0  2018-06-01  2018-06-21  4.663569  4.665780  0.002210  \n",
       "38677  dt_0  2018-06-01  2018-06-21  4.780209  4.787802  0.007593  \n",
       "38678  dt_0  2018-06-01  2018-06-21  4.875618  4.903659  0.028041  \n",
       "38679  dt_0  2018-06-01  2018-06-21  4.970114  4.974202  0.004088  \n",
       "38680  dt_0  2018-06-01  2018-06-21  5.917675  5.955576  0.037901  \n",
       "\n",
       "[38681 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "female-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_df.to_csv(r\"C:\\my_packages\\doc_data\\profiles\\dh_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3baa3cb",
   "metadata": {},
   "source": [
    "## Create Dataframe of details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb2f6b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>date_pre</th>\n",
       "      <th>date_post</th>\n",
       "      <th>location</th>\n",
       "      <th>n_days</th>\n",
       "      <th>loc_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt_0</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>mar</td>\n",
       "      <td>20</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt_1</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>mar</td>\n",
       "      <td>36</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt_2</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>mar</td>\n",
       "      <td>60</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dt_3</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>mar</td>\n",
       "      <td>49</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dt_4</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>mar</td>\n",
       "      <td>28</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dt_5</td>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>mar</td>\n",
       "      <td>56</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dt_6</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>2019-03-13</td>\n",
       "      <td>mar</td>\n",
       "      <td>36</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dt_7</td>\n",
       "      <td>2019-03-13</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>mar</td>\n",
       "      <td>64</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dt_0</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>leo</td>\n",
       "      <td>37</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dt_1</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>leo</td>\n",
       "      <td>12</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dt_2</td>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>leo</td>\n",
       "      <td>57</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dt_3</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>leo</td>\n",
       "      <td>144</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dt_4</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>leo</td>\n",
       "      <td>45</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dt_5</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>leo</td>\n",
       "      <td>125</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dt    date_pre   date_post location  n_days      loc_full\n",
       "0   dt_0  2018-06-01  2018-06-21      mar      20       Marengo\n",
       "1   dt_1  2018-06-21  2018-07-27      mar      36       Marengo\n",
       "2   dt_2  2018-07-27  2018-09-25      mar      60       Marengo\n",
       "3   dt_3  2018-09-25  2018-11-13      mar      49       Marengo\n",
       "4   dt_4  2018-11-13  2018-12-11      mar      28       Marengo\n",
       "5   dt_5  2018-12-11  2019-02-05      mar      56       Marengo\n",
       "6   dt_6  2019-02-05  2019-03-13      mar      36       Marengo\n",
       "7   dt_7  2019-03-13  2019-05-16      mar      64       Marengo\n",
       "8   dt_0  2018-06-06  2018-07-13      leo      37  St. Leonards\n",
       "9   dt_1  2018-07-13  2018-07-25      leo      12  St. Leonards\n",
       "10  dt_2  2018-07-25  2018-09-20      leo      57  St. Leonards\n",
       "11  dt_3  2018-09-20  2019-02-11      leo     144  St. Leonards\n",
       "12  dt_4  2019-02-11  2019-03-28      leo      45  St. Leonards\n",
       "13  dt_5  2019-03-28  2019-07-31      leo     125  St. Leonards"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_details_df(dh_df, loc_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcd1f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_dt_str.to_csv(r\"C:\\my_packages\\doc_data\\profiles\\dt_info.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
