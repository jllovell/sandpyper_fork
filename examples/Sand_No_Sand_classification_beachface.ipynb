{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "civic-indonesian",
   "metadata": {},
   "source": [
    "<img src=\"images/banner3.png\" width=\"100%\" />\n",
    "\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Sand classification, beachface clipping and multitemporal analysis</b></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Nicolas Pucino; PhD Student @ Deakin University, Australia </b> <br>\n",
    "<img style=\"padding:7px;\" src=\"images/sandpiper_sand_retouched.png\" width=\"170\" align=\"right\" /></font>\n",
    "\n",
    "<font size=\"3\">This notebook illustrates how to use assign the final Sand or no-sand labels to the points, clip only beachface areas and create an organised dataframe storing elevation changes from each period available in all locations. <br>\n",
    "\n",
    "<b>This notebook covers the following concepts:</b>\n",
    "\n",
    "- Sand vs No-Sand classification.\n",
    "- Beachface clipping.\n",
    "- Multitemporal extraction\n",
    "</font>\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "satisfied-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "revolutionary-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_dataset=pd.read_csv(r\"C:\\my_packages\\doc_data\\labels\\data_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "european-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QGIS Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "infectious-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionaries and lists\n",
    "\n",
    "labels_dict={\"water\":0,\n",
    "            \"sand\":1,\n",
    "            \"vegetation\":2,\n",
    "            \"no_sand\":3}\n",
    "\n",
    "labels_sand=[1]\n",
    "labels_no_sand=[0,2,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "floppy-liberia",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "water_dict= {'mar_20180601': [],\n",
    " 'inv_20201020': [],\n",
    " 'inv_20200826': []}\n",
    "\n",
    "no_sand_dict={'inv_20201211': [7],\n",
    " 'inv_20201020': [],\n",
    " 'inv_20200826': []}\n",
    "\n",
    "veg_dict={'inv_20201211': [],\n",
    " 'inv_20201020': [],\n",
    " 'inv_20200826': []}\n",
    "\n",
    "sand_dict={'mar_20180601: [3,5,8,9],\n",
    " 'inv_20201020': [0,2,3,6,7,8],\n",
    " 'inv_20200826': [1,3,4,7,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "acceptable-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4225f520c354aa399200fabad5eee54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv.\n",
      "Working on: inv_20201211.\n",
      "inv_20201211, evaluating WATER.\n",
      "inv_20201211, evaluating SAND.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npucino\\AppData\\Local\\Continuum\\anaconda3\\envs\\transectenvi\\lib\\site-packages\\ipykernel\\__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_20201211, evaluating VEG.\n",
      "inv_20201211, evaluating NO_SAND.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npucino\\AppData\\Local\\Continuum\\anaconda3\\envs\\transectenvi\\lib\\site-packages\\ipykernel\\__main__.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In inv_20201211, the remaining labels [1, 4, 2, 6] are classified as no_sand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npucino\\AppData\\Local\\Continuum\\anaconda3\\envs\\transectenvi\\lib\\site-packages\\ipykernel\\__main__.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: inv_20201020.\n",
      "inv_20201020, evaluating WATER.\n",
      "inv_20201020, evaluating SAND.\n",
      "inv_20201020, evaluating VEG.\n",
      "inv_20201020, evaluating NO_SAND.\n",
      "In inv_20201020, the remaining labels [9, 5, 4, 1] are classified as no_sand.\n",
      "Working on: inv_20200826.\n",
      "inv_20200826, evaluating WATER.\n",
      "inv_20200826, evaluating SAND.\n",
      "inv_20200826, evaluating VEG.\n",
      "inv_20200826, evaluating NO_SAND.\n",
      "In inv_20200826, the remaining labels [6, 0, 9, 5, 2] are classified as no_sand.\n",
      "\n",
      "Checking for duplicated rows . . . \n",
      "Reclassification run successfully!\n",
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# classify sand VS no-sand\n",
    "\n",
    "df_labels=labelled_dataset\n",
    "\n",
    "corrected_labelled_df=pd.DataFrame()\n",
    "list_locs=labelled_dataset.location.unique()\n",
    "\n",
    "for location in tqdm(list_locs):\n",
    "    \n",
    "    print(f\"{location}.\")\n",
    "    \n",
    "    list_dates = df_labels.query(f\"location=='{location}'\").raw_date.unique()\n",
    "    \n",
    "    for survey_date in list_dates:\n",
    "                        \n",
    "        dataset_str=f\"{location}_{survey_date}\"\n",
    "        print(f\"Working on: {dataset_str}.\")\n",
    "        data_in=df_labels.query(f\"location=='{location}' & raw_date=='{survey_date}'\")\n",
    "        \n",
    "\n",
    "        list_labels=data_in.label_k.unique()   \n",
    "\n",
    "        # water\n",
    "        try:\n",
    "            print(f\"{dataset_str}, evaluating WATER.\")\n",
    "            label_df=data_in.query(f\"label_k == {water_dict[dataset_str]} \")\n",
    "            label_df[\"opt_label\"]=labels_dict[\"water\"]\n",
    "            corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "            list_labels=[e for e in list_labels if e not in water_dict[dataset_str]]\n",
    "        \n",
    "        except:\n",
    "            print(f\"{dataset_str} does not have water classes\")\n",
    "\n",
    "        # sand\n",
    "        try:\n",
    "            print(f\"{dataset_str}, evaluating SAND.\")\n",
    "            label_df=data_in.query(f\"label_k == {sand_dict[dataset_str]} \")\n",
    "            label_df[\"opt_label\"]=labels_dict[\"sand\"]\n",
    "            corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "            list_labels=[e for e in list_labels if e not in sand_dict[dataset_str]]\n",
    "\n",
    "        except:\n",
    "            print(f\"{dataset_str} does not have sand classes\")\n",
    "\n",
    "        # veg\n",
    "        try:\n",
    "            print(f\"{dataset_str}, evaluating VEG.\")\n",
    "            label_df=data_in.query(f\"label_k == {veg_dict[dataset_str]} \")\n",
    "            label_df[\"opt_label\"]=labels_dict[\"vegetation\"]\n",
    "            corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "            list_labels=[e for e in list_labels if e not in veg_dict[dataset_str]]\n",
    "            \n",
    "        except:\n",
    "            print(f\"{dataset_str} does not have vegetation classes\")\n",
    "\n",
    "        # no_sand\n",
    "        try:\n",
    "            print(f\"{dataset_str}, evaluating NO_SAND.\")\n",
    "            label_df=data_in.query(f\"label_k == {no_sand_dict[dataset_str]} \")\n",
    "            label_df[\"opt_label\"]=labels_dict[\"no_sand\"]\n",
    "            corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "            list_labels=[e for e in list_labels if e not in no_sand_dict[dataset_str]]\n",
    "        except:\n",
    "            print(f\"{dataset_str} does not have no_sand classes\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        print(f\"In {dataset_str}, the remaining labels {list_labels} are classified as no_sand.\")\n",
    "            \n",
    "        label_df=data_in.query(f\"label_k == {list_labels} \")\n",
    "        label_df[\"opt_label\"]=labels_dict[\"no_sand\"]            \n",
    "        corrected_labelled_df=pd.concat([label_df,corrected_labelled_df], ignore_index=True)\n",
    "\n",
    "print(\"Checking for duplicated rows . . . \")\n",
    "\n",
    "if corrected_labelled_df.point_id.is_unique == False:\n",
    "    \n",
    "    print(\"There are some duplicated labels in the dictioanries. Run \"'duplicated_df.groupby(by=[\"location\",\"survey_date\",\"label_k\"]).count()'\" to find out. PLease correct them and re-run the cell. \")\n",
    "    # Select duplicate rows \n",
    "    duplicated_df = corrected_labelled_df[corrected_labelled_df.duplicated(['point_id'])]\n",
    "    duplicated_df.groupby(by=[\"location\",\"survey_date\",\"label_k\"]).count()\n",
    "else:\n",
    "    \n",
    "    print(\"Reclassification run successfully!\")\n",
    "\n",
    "\n",
    "corrected_labelled_df['sand_label'] = [ 1 if s in labels_no_sand else 0 for s in corrected_labelled_df.opt_label.values]\n",
    "corrected_labelled_df.sand_label.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "medieval-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>z</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>point_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "      <th>band1</th>\n",
       "      <th>band2</th>\n",
       "      <th>band3</th>\n",
       "      <th>slope</th>\n",
       "      <th>curve</th>\n",
       "      <th>label_k</th>\n",
       "      <th>opt_label</th>\n",
       "      <th>sand_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.416860</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389485.0292927367 5722796.792901353)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22837030600in006</td>\n",
       "      <td>389485.0292927367</td>\n",
       "      <td>5722796.792901353</td>\n",
       "      <td>POINT (389485.029 5722796.793)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-2.766547</td>\n",
       "      <td>1.376038</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.419285</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389485.0122613082 5722796.891440332)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22832000810in006</td>\n",
       "      <td>389485.0122613082</td>\n",
       "      <td>5722796.891440332</td>\n",
       "      <td>POINT (389485.012 5722796.891)</td>\n",
       "      <td>93.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-0.002408</td>\n",
       "      <td>1.382086</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.421676</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389484.9952298797 5722796.989979312)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22837070920in006</td>\n",
       "      <td>389484.9952298797</td>\n",
       "      <td>5722796.989979312</td>\n",
       "      <td>POINT (389484.995 5722796.990)</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-0.002375</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.424035</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389484.9781984512 5722797.088518291)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22832050130in006</td>\n",
       "      <td>389484.97819845116</td>\n",
       "      <td>5722797.088518291</td>\n",
       "      <td>POINT (389484.978 5722797.089)</td>\n",
       "      <td>85.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-0.002343</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.426361</td>\n",
       "      <td>163</td>\n",
       "      <td>20200826</td>\n",
       "      <td>POINT (389484.9611670226 5722797.18705727)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2601v22836020240in006</td>\n",
       "      <td>389484.96116702264</td>\n",
       "      <td>5722797.18705727</td>\n",
       "      <td>POINT (389484.961 5722797.187)</td>\n",
       "      <td>88.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-0.003679</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320347</td>\n",
       "      <td>92.5</td>\n",
       "      <td>3.377417</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.7613396471 5721639.905428521)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10204001i2272101nv95</td>\n",
       "      <td>386871.7613396471</td>\n",
       "      <td>5721639.905428521</td>\n",
       "      <td>POINT (386871.761 5721639.905)</td>\n",
       "      <td>97.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320348</td>\n",
       "      <td>92.6</td>\n",
       "      <td>3.402572</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.7460518774 5721640.004253033)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10207001i2272401nv96</td>\n",
       "      <td>386871.7460518774</td>\n",
       "      <td>5721640.004253033</td>\n",
       "      <td>POINT (386871.746 5721640.004)</td>\n",
       "      <td>86.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>-0.006844</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320349</td>\n",
       "      <td>92.7</td>\n",
       "      <td>3.402572</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.7307641076 5721640.103077544)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10200001i2272601nv97</td>\n",
       "      <td>386871.7307641076</td>\n",
       "      <td>5721640.103077544</td>\n",
       "      <td>POINT (386871.731 5721640.103)</td>\n",
       "      <td>101.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.006841</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320350</td>\n",
       "      <td>92.8</td>\n",
       "      <td>3.400400</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.7154763379 5721640.201902056)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10203001i2272901nv98</td>\n",
       "      <td>386871.7154763379</td>\n",
       "      <td>5721640.201902056</td>\n",
       "      <td>POINT (386871.715 5721640.202)</td>\n",
       "      <td>103.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>-0.006097</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320351</td>\n",
       "      <td>93.3</td>\n",
       "      <td>3.373779</td>\n",
       "      <td>0</td>\n",
       "      <td>20201211</td>\n",
       "      <td>POINT (386871.6390374891 5721640.696024614)</td>\n",
       "      <td>inv</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>10208001i2293101nv93</td>\n",
       "      <td>386871.6390374891</td>\n",
       "      <td>5721640.696024614</td>\n",
       "      <td>POINT (386871.639 5721640.696)</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-0.012963</td>\n",
       "      <td>-0.007356</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320352 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance         z tr_id  raw_date  \\\n",
       "0            0.0 -0.416860   163  20200826   \n",
       "1            0.1 -0.419285   163  20200826   \n",
       "2            0.2 -0.421676   163  20200826   \n",
       "3            0.3 -0.424035   163  20200826   \n",
       "4            0.4 -0.426361   163  20200826   \n",
       "...          ...       ...   ...       ...   \n",
       "320347      92.5  3.377417     0  20201211   \n",
       "320348      92.6  3.402572     0  20201211   \n",
       "320349      92.7  3.402572     0  20201211   \n",
       "320350      92.8  3.400400     0  20201211   \n",
       "320351      93.3  3.373779     0  20201211   \n",
       "\n",
       "                                        coordinates location survey_date  \\\n",
       "0       POINT (389485.0292927367 5722796.792901353)      inv  2020-08-26   \n",
       "1       POINT (389485.0122613082 5722796.891440332)      inv  2020-08-26   \n",
       "2       POINT (389484.9952298797 5722796.989979312)      inv  2020-08-26   \n",
       "3       POINT (389484.9781984512 5722797.088518291)      inv  2020-08-26   \n",
       "4        POINT (389484.9611670226 5722797.18705727)      inv  2020-08-26   \n",
       "...                                             ...      ...         ...   \n",
       "320347  POINT (386871.7613396471 5721639.905428521)      inv  2020-12-11   \n",
       "320348  POINT (386871.7460518774 5721640.004253033)      inv  2020-12-11   \n",
       "320349  POINT (386871.7307641076 5721640.103077544)      inv  2020-12-11   \n",
       "320350  POINT (386871.7154763379 5721640.201902056)      inv  2020-12-11   \n",
       "320351  POINT (386871.6390374891 5721640.696024614)      inv  2020-12-11   \n",
       "\n",
       "                     point_id                   x                  y  \\\n",
       "0       2601v22837030600in006   389485.0292927367  5722796.792901353   \n",
       "1       2601v22832000810in006   389485.0122613082  5722796.891440332   \n",
       "2       2601v22837070920in006   389484.9952298797  5722796.989979312   \n",
       "3       2601v22832050130in006  389484.97819845116  5722797.088518291   \n",
       "4       2601v22836020240in006  389484.96116702264   5722797.18705727   \n",
       "...                       ...                 ...                ...   \n",
       "320347   10204001i2272101nv95   386871.7613396471  5721639.905428521   \n",
       "320348   10207001i2272401nv96   386871.7460518774  5721640.004253033   \n",
       "320349   10200001i2272601nv97   386871.7307641076  5721640.103077544   \n",
       "320350   10203001i2272901nv98   386871.7154763379  5721640.201902056   \n",
       "320351   10208001i2293101nv93   386871.6390374891  5721640.696024614   \n",
       "\n",
       "                              geometry  band1  band2 band3     slope  \\\n",
       "0       POINT (389485.029 5722796.793)   94.0   91.0  95.0 -2.766547   \n",
       "1       POINT (389485.012 5722796.891)   93.0   89.0  93.0 -0.002408   \n",
       "2       POINT (389484.995 5722796.990)   89.0   85.0  89.0 -0.002375   \n",
       "3       POINT (389484.978 5722797.089)   85.0   83.0  86.0 -0.002343   \n",
       "4       POINT (389484.961 5722797.187)   88.0   85.0  91.0 -0.003679   \n",
       "...                                ...    ...    ...   ...       ...   \n",
       "320347  POINT (386871.761 5721639.905)   97.0  116.0  70.0  0.012603   \n",
       "320348  POINT (386871.746 5721640.004)   86.0  112.0  61.0  0.012578   \n",
       "320349  POINT (386871.731 5721640.103)  101.0  128.0  76.0 -0.001086   \n",
       "320350  POINT (386871.715 5721640.202)  103.0  127.0  76.0 -0.001105   \n",
       "320351  POINT (386871.639 5721640.696)  103.0  112.0  87.0 -0.012963   \n",
       "\n",
       "           curve  label_k  opt_label  sand_label  \n",
       "0       1.376038        6          3           1  \n",
       "1       1.382086        6          3           1  \n",
       "2       0.000033        0          3           1  \n",
       "3      -0.000652        0          3           1  \n",
       "4      -0.000640        0          3           1  \n",
       "...          ...      ...        ...         ...  \n",
       "320347  0.006434        9          1           0  \n",
       "320348 -0.006844        9          1           0  \n",
       "320349 -0.006841        9          1           0  \n",
       "320350 -0.006097        9          1           0  \n",
       "320351 -0.007356        9          1           0  \n",
       "\n",
       "[320352 rows x 19 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a geodataframe with point objects\n",
    "\n",
    "corrected_labelled_df = corrected_labelled_df.loc[:,~corrected_labelled_df.columns.duplicated()] # eliminate duplicated columns\n",
    "corrected_labelled_df['geometry']=corrected_labelled_df.coordinates.apply(coords_to_points) # create Point objects\n",
    "corrected_labelled_gdf=gpd.GeoDataFrame(corrected_labelled_df, geometry='geometry', crs=crs_dict_string['inv']) # create GeoDataFrame\n",
    "corrected_labelled_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "varied-ceramic",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chloe_vali_noSand' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1322a6ac68b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchloe_vali_noSand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'chloe_vali_noSand' is not defined"
     ]
    }
   ],
   "source": [
    "chloe_vali_noSand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "appropriate-threshold",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_Not_Sand.gpkg: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_Not_Sand.gpkg: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\conda3\\envs\\sandpiper_env\\lib\\site-packages\\geopandas\\io\\file.py\u001b[0m in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda3\\envs\\sandpiper_env\\lib\\site-packages\\fiona\\env.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda3\\envs\\sandpiper_env\\lib\\site-packages\\fiona\\__init__.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[1;32m--> 257\u001b[1;33m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda3\\envs\\sandpiper_env\\lib\\site-packages\\fiona\\collection.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_Not_Sand.gpkg: No such file or directory"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# apply poly correction with geopandas\n",
    "\n",
    "#labelled_gdf=corrected_labelled_gdf\n",
    "corr_date_field='survey_date'\n",
    "labelled_df_date_field='raw_date'\n",
    "\n",
    "is_sand_path=r\"E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_ToSand.gpkg\"\n",
    "is_not_sand_path=r\"E:\\chapter_4\\chloe_inv\\add3\\labels\\chloe_add3_Not_Sand.gpkg\"\n",
    "shore_path=r\"C:\\jupyter\\shore_areas\\inv_shore.gpkg\"\n",
    "\n",
    "#____________\n",
    "chloe_vali_noSand=gpd.read_file(is_not_sand_path)\n",
    "\n",
    "if '-' in chloe_vali_noSand.loc[:,corr_date_field].any():\n",
    "    chloe_vali_noSand.loc[:,corr_date_field]=chloe_vali_noSand.loc[:,corr_date_field].apply(lambda x: x.replace('-',''))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if corr_date_field != 'date_raw':\n",
    "    chloe_vali_noSand.rename({corr_date_field:'date_raw'}, axis=1, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "chloe_vali_Sand=gpd.read_file(is_sand_path)\n",
    "\n",
    "if '-' in chloe_vali_Sand.loc[:,corr_date_field].any():\n",
    "    chloe_vali_Sand.loc[:,corr_date_field]=chloe_vali_Sand.loc[:,corr_date_field].apply(lambda x: x.replace('-',''))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if corr_date_field != 'date_raw':\n",
    "    chloe_vali_Sand.rename({corr_date_field:'date_raw'}, axis=1, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "# check wether the correction geopackages are empty or not. If empty, skip correction.\n",
    "if chloe_vali_Sand.empty:\n",
    "    skip_isSand=True\n",
    "    print(\"Correction TO SAND skipped as the provided file is empty.\")\n",
    "else:\n",
    "    skip_isSand=False\n",
    "    \n",
    "if chloe_vali_noSand.empty:\n",
    "    skip_NoSand=True\n",
    "    print(\"Correction TO NO-SAND skipped as the provided file is empty.\")\n",
    "else:\n",
    "    skip_NoSand=False\n",
    "    \n",
    "\n",
    "# Poly correction starts here______________________________________\n",
    "\n",
    "to_update=pd.DataFrame()\n",
    "\n",
    "for date_in in labelled_gdf.loc[:,labelled_df_date_field].unique():\n",
    "\n",
    "    #subset points and polygones based on date\n",
    "    data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}'\")\n",
    "    vali_isSand=chloe_vali_Sand.query(f\"date_raw == '{date_in}'\")\n",
    "    vali_NoSand=chloe_vali_noSand.query(f\"date_raw == '{date_in}'\")\n",
    "    \n",
    "    # first set what IS SAND\n",
    "    if bool(skip_isSand)==True or vali_isSand.empty:\n",
    "        pass\n",
    "    else:\n",
    "        for i in range(vali_isSand.shape[0]): # loops through all the polygones\n",
    "\n",
    "            target_k=int(vali_isSand.iloc[i]['target_label_k'])\n",
    "\n",
    "            if target_k != 999:\n",
    "\n",
    "                data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}' & label_k=='{target_k}'\")\n",
    "                selection=data_in[data_in.geometry.intersects(vali_isSand.geometry.iloc[i])]\n",
    "                selection[\"corr_label\"]=0\n",
    "\n",
    "            elif target_k == 999:\n",
    "\n",
    "                data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}'\")\n",
    "                selection=data_in[data_in.geometry.intersects(vali_isSand.geometry.iloc[i])]\n",
    "                selection[\"corr_label\"]=0\n",
    "\n",
    "        to_update=pd.concat([selection,to_update], ignore_index=True)\n",
    "        \n",
    "            \n",
    "    # Now set what IS NOT SAND\n",
    "    if skip_NoSand or vali_NoSand.empty:\n",
    "        pass\n",
    "    else:\n",
    "        for i in range(vali_NoSand.shape[0]): # loops through all the polygones\n",
    "\n",
    "            target_k=int(vali_NoSand.iloc[i]['target_label_k'])\n",
    "\n",
    "            if target_k != 999:\n",
    "\n",
    "                data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}' & label_k=='{target_k}'\")\n",
    "                selection=data_in[data_in.geometry.intersects(vali_NoSand.geometry.iloc[i])]\n",
    "                selection[\"corr_label\"]=1\n",
    "\n",
    "            elif target_k == 999:\n",
    "\n",
    "                data_in=labelled_gdf.query(f\"{labelled_df_date_field} == '{date_in}'\")\n",
    "                selection=data_in[data_in.geometry.intersects(vali_NoSand.geometry.iloc[i])]\n",
    "                selection[\"corr_label\"]=1\n",
    "\n",
    "        to_update=pd.concat([selection,to_update], ignore_index=True)\n",
    "    \n",
    "to_update.drop_duplicates(subset=\"point_id\", inplace=True)\n",
    "\n",
    "\n",
    "#__CREATE NEW UPDATED DATAFRAME____________________________\n",
    "labelled_df_updated=pd.merge(left=labelled_gdf, right=to_update.loc[:,['point_id','corr_label']], # Left Join \n",
    "                             how='left', validate='one_to_one') \n",
    "labelled_df_updated.corr_label.fillna(labelled_df_updated.sand_label, inplace=True) # Fill NaN with previous sand labels\n",
    "labelled_df_updated[\"corr_label\"]=labelled_df_updated.corr_label.astype(int) # Transform corr_labels in Int\n",
    "\n",
    "#__CLIP BY SHORE____________________________\n",
    "shore=gpd.read_file(shore_path)\n",
    "in_shore=labelled_df_updated[labelled_df_updated.geometry.intersects(shore.geometry.iloc[0])]\n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "in_shore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "novel-appeal",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_shore.to_csv(r\"E:\\chapter_4\\chloe_inv\\add3\\labels\\add3_inv_labelled_inshore.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd28f04",
   "metadata": {},
   "source": [
    "### Create multitemporal datased (dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stylish-concord",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'location' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-047921aead8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdate_field\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'survey_date'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msand_label_field\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'label_sand'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mloc_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"location=='{location}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlist_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloc_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdate_field\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'location' is not defined"
     ]
    }
   ],
   "source": [
    "## Multitemporal Extraction to loop trough locations\n",
    "\n",
    "full_dataset=pd.read_csv(r\"C:\\my_packages\\doc_data\\profiles\\classified_data.csv\")\n",
    "\n",
    "date_field='survey_date'\n",
    "sand_label_field='label_sand'\n",
    "loc_data=full_dataset.query(f\"location=='{location}'\")\n",
    "\n",
    "list_dates=loc_data.loc[:,date_field].unique()\n",
    "list_dates.sort()\n",
    "list_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c35ccb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>point_id</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>z</th>\n",
       "      <th>tr_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>label_sand</th>\n",
       "      <th>spatial_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64173</th>\n",
       "      <td>64173</td>\n",
       "      <td>20262080010a8r0m41</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>0.926513</td>\n",
       "      <td>24</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0ma2r0428</td>\n",
       "      <td>POINT (731623.7909041131 5705539.273920873)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64174</th>\n",
       "      <td>64174</td>\n",
       "      <td>a24008r012811600m2</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>0.899809</td>\n",
       "      <td>24</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0ma2r1428</td>\n",
       "      <td>POINT (731623.7083581986 5705539.33036706)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64175</th>\n",
       "      <td>64175</td>\n",
       "      <td>6ra08010012m840222</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>0.854644</td>\n",
       "      <td>24</td>\n",
       "      <td>28.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0ma2r2428</td>\n",
       "      <td>POINT (731623.6258122841 5705539.386813247)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64176</th>\n",
       "      <td>64176</td>\n",
       "      <td>a01102248m208r3006</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>0.841955</td>\n",
       "      <td>24</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0ma2r3428</td>\n",
       "      <td>POINT (731623.5432663695 5705539.443259434)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64177</th>\n",
       "      <td>64177</td>\n",
       "      <td>01m02464r020a81802</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>0.829797</td>\n",
       "      <td>24</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0ma2r4428</td>\n",
       "      <td>POINT (731623.460720455 5705539.49970562)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70551</th>\n",
       "      <td>70551</td>\n",
       "      <td>000m6214r500a8231</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>5.952633</td>\n",
       "      <td>3</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0</td>\n",
       "      <td>03ar2m54</td>\n",
       "      <td>POINT (731458.573472786 5705157.393759999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70564</th>\n",
       "      <td>70564</td>\n",
       "      <td>a050112r5603050m8</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>6.250172</td>\n",
       "      <td>3</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0</td>\n",
       "      <td>03ar5m55</td>\n",
       "      <td>POINT (731457.2809620509 5705157.533101305)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70565</th>\n",
       "      <td>70565</td>\n",
       "      <td>505a06131208rm060</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>6.224430</td>\n",
       "      <td>3</td>\n",
       "      <td>55.6</td>\n",
       "      <td>0</td>\n",
       "      <td>03ar6m55</td>\n",
       "      <td>POINT (731457.1815381482 5705157.543819867)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70566</th>\n",
       "      <td>70566</td>\n",
       "      <td>2800317a00m1650r5</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>6.150842</td>\n",
       "      <td>3</td>\n",
       "      <td>55.7</td>\n",
       "      <td>0</td>\n",
       "      <td>03ar7m55</td>\n",
       "      <td>POINT (731457.0821142454 5705157.554538429)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70567</th>\n",
       "      <td>70567</td>\n",
       "      <td>08ra601200051m583</td>\n",
       "      <td>mar</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>6.053431</td>\n",
       "      <td>3</td>\n",
       "      <td>55.8</td>\n",
       "      <td>0</td>\n",
       "      <td>03ar8m55</td>\n",
       "      <td>POINT (731456.9826903427 5705157.565256991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4573 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0            point_id location survey_date         z  tr_id  \\\n",
       "64173       64173  20262080010a8r0m41      mar  2018-06-01  0.926513     24   \n",
       "64174       64174  a24008r012811600m2      mar  2018-06-01  0.899809     24   \n",
       "64175       64175  6ra08010012m840222      mar  2018-06-01  0.854644     24   \n",
       "64176       64176  a01102248m208r3006      mar  2018-06-01  0.841955     24   \n",
       "64177       64177  01m02464r020a81802      mar  2018-06-01  0.829797     24   \n",
       "...           ...                 ...      ...         ...       ...    ...   \n",
       "70551       70551   000m6214r500a8231      mar  2018-06-01  5.952633      3   \n",
       "70564       70564   a050112r5603050m8      mar  2018-06-01  6.250172      3   \n",
       "70565       70565   505a06131208rm060      mar  2018-06-01  6.224430      3   \n",
       "70566       70566   2800317a00m1650r5      mar  2018-06-01  6.150842      3   \n",
       "70567       70567   08ra601200051m583      mar  2018-06-01  6.053431      3   \n",
       "\n",
       "       distance  label_sand spatial_id  \\\n",
       "64173      28.0           0  0ma2r0428   \n",
       "64174      28.1           0  0ma2r1428   \n",
       "64175      28.2           0  0ma2r2428   \n",
       "64176      28.3           0  0ma2r3428   \n",
       "64177      28.4           0  0ma2r4428   \n",
       "...         ...         ...        ...   \n",
       "70551      54.2           0   03ar2m54   \n",
       "70564      55.5           0   03ar5m55   \n",
       "70565      55.6           0   03ar6m55   \n",
       "70566      55.7           0   03ar7m55   \n",
       "70567      55.8           0   03ar8m55   \n",
       "\n",
       "                                          geometry  \n",
       "64173  POINT (731623.7909041131 5705539.273920873)  \n",
       "64174   POINT (731623.7083581986 5705539.33036706)  \n",
       "64175  POINT (731623.6258122841 5705539.386813247)  \n",
       "64176  POINT (731623.5432663695 5705539.443259434)  \n",
       "64177    POINT (731623.460720455 5705539.49970562)  \n",
       "...                                            ...  \n",
       "70551   POINT (731458.573472786 5705157.393759999)  \n",
       "70564  POINT (731457.2809620509 5705157.533101305)  \n",
       "70565  POINT (731457.1815381482 5705157.543819867)  \n",
       "70566  POINT (731457.0821142454 5705157.554538429)  \n",
       "70567  POINT (731456.9826903427 5705157.565256991)  \n",
       "\n",
       "[4573 rows x 10 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_data.query(f\"{date_field} =='{date_pre}' & {sand_label_field} == 0\").dropna(subset=['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "constant-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multitemporal Extraction to loop trough locations\n",
    "\n",
    "def compute_multitemporal (df,\n",
    "                           date_field='survey_date',\n",
    "                          sand_label_field='label_sand',\n",
    "                          common_field=\"geometry\"):\n",
    "\n",
    "\n",
    "\n",
    "    fusion_long=pd.DataFrame()\n",
    "\n",
    "    for location in full_dataset.location.unique():\n",
    "        print(f\"working on {location}\")\n",
    "        loc_data=full_dataset.query(f\"location=='{location}'\")\n",
    "        list_dates=loc_data.loc[:,date_field].unique()\n",
    "        list_dates.sort()\n",
    "\n",
    "\n",
    "        for i in tqdm(range(list_dates.shape[0])):\n",
    "\n",
    "            if i < list_dates.shape[0]-1:\n",
    "                date_pre=list_dates[i]\n",
    "                date_post=list_dates[i+1]\n",
    "                print(f\"Calculating dt{i}, from {date_pre} to {date_post} in {location}.\")\n",
    "\n",
    "                df_pre=loc_data.query(f\"{date_field} =='{date_pre}' & {sand_label_field} == 0\").dropna(subset=['z'])\n",
    "                df_post=loc_data.query(f\"{date_field} =='{date_post}' & {sand_label_field} == 0\").dropna(subset=['z'])\n",
    "\n",
    "                merged=pd.merge(df_pre,df_post, how='inner', on=common_field,validate=\"one_to_one\",suffixes=('_pre','_post'))\n",
    "                merged[\"dh\"]=merged.z_post.astype(float) - merged.z_pre.astype(float)\n",
    "\n",
    "                dict_short={\"geometry\": merged.geometry,\n",
    "                            \"location\":location,\n",
    "                            \"tr_id\":merged.tr_id_pre,\n",
    "                            \"distance\":merged.distance_pre,\n",
    "                            \"dt\":  f\"dt_{i}\",\n",
    "                            \"date_pre\":date_pre,\n",
    "                            \"date_post\":date_post,\n",
    "                            \"z_pre\":merged.z_pre.astype(float),\n",
    "                            \"z_post\":merged.z_post.astype(float),\n",
    "                            \"dh\":merged.dh}\n",
    "\n",
    "                short_df=pd.DataFrame(dict_short)\n",
    "                fusion_long=pd.concat([short_df,fusion_long],ignore_index=True)\n",
    "\n",
    "    print(\"done\")\n",
    "    return fusion_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a1614d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset=pd.read_csv(r\"C:\\my_packages\\doc_data\\profiles\\classified_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d31782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 3/9 [00:00<00:00, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on mar\n",
      "Calculating dt0, from 2018-06-01 to 2018-06-21 in mar.\n",
      "Calculating dt1, from 2018-06-21 to 2018-07-27 in mar.\n",
      "Calculating dt2, from 2018-07-27 to 2018-09-25 in mar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 6/9 [00:00<00:00, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dt3, from 2018-09-25 to 2018-11-13 in mar.\n",
      "Calculating dt4, from 2018-11-13 to 2018-12-11 in mar.\n",
      "Calculating dt5, from 2018-12-11 to 2019-02-05 in mar.\n",
      "Calculating dt6, from 2019-02-05 to 2019-03-13 in mar.\n",
      "Calculating dt7, from 2019-03-13 to 2019-05-16 in mar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 23.44it/s]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:00<00:00, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on leo\n",
      "Calculating dt0, from 2018-06-06 to 2018-07-13 in leo.\n",
      "Calculating dt1, from 2018-07-13 to 2018-07-25 in leo.\n",
      "Calculating dt2, from 2018-07-25 to 2018-09-20 in leo.\n",
      "Calculating dt3, from 2018-09-20 to 2019-02-11 in leo.\n",
      "Calculating dt4, from 2019-02-11 to 2019-03-28 in leo.\n",
      "Calculating dt5, from 2019-03-28 to 2019-07-31 in leo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 33.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dh_df=compute_multitemporal(full_dataset,\n",
    "                      date_field='survey_date',\n",
    "                      sand_label_field='label_sand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "female-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_df.to_csv(r\"C:\\my_packages\\doc_data\\profiles\\dh_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa08813",
   "metadata": {},
   "source": [
    "### Create Dataframe of details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89ee726d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>date_pre</th>\n",
       "      <th>date_post</th>\n",
       "      <th>location</th>\n",
       "      <th>n_days</th>\n",
       "      <th>loc_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt_0</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>mar</td>\n",
       "      <td>20</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt_1</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>mar</td>\n",
       "      <td>36</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt_2</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>mar</td>\n",
       "      <td>60</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dt_3</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>mar</td>\n",
       "      <td>49</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dt_4</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>mar</td>\n",
       "      <td>28</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dt_5</td>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>mar</td>\n",
       "      <td>56</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dt_6</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>2019-03-13</td>\n",
       "      <td>mar</td>\n",
       "      <td>36</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dt_7</td>\n",
       "      <td>2019-03-13</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>mar</td>\n",
       "      <td>64</td>\n",
       "      <td>Marengo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dt_0</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>leo</td>\n",
       "      <td>37</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dt_1</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>leo</td>\n",
       "      <td>12</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dt_2</td>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>leo</td>\n",
       "      <td>57</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dt_3</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>leo</td>\n",
       "      <td>144</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dt_4</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>leo</td>\n",
       "      <td>45</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dt_5</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>leo</td>\n",
       "      <td>125</td>\n",
       "      <td>St. Leonards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dt    date_pre   date_post location  n_days      loc_full\n",
       "0   dt_0  2018-06-01  2018-06-21      mar      20       Marengo\n",
       "1   dt_1  2018-06-21  2018-07-27      mar      36       Marengo\n",
       "2   dt_2  2018-07-27  2018-09-25      mar      60       Marengo\n",
       "3   dt_3  2018-09-25  2018-11-13      mar      49       Marengo\n",
       "4   dt_4  2018-11-13  2018-12-11      mar      28       Marengo\n",
       "5   dt_5  2018-12-11  2019-02-05      mar      56       Marengo\n",
       "6   dt_6  2019-02-05  2019-03-13      mar      36       Marengo\n",
       "7   dt_7  2019-03-13  2019-05-16      mar      64       Marengo\n",
       "8   dt_0  2018-06-06  2018-07-13      leo      37  St. Leonards\n",
       "9   dt_1  2018-07-13  2018-07-25      leo      12  St. Leonards\n",
       "10  dt_2  2018-07-25  2018-09-20      leo      57  St. Leonards\n",
       "11  dt_3  2018-09-20  2019-02-11      leo     144  St. Leonards\n",
       "12  dt_4  2019-02-11  2019-03-28      leo      45  St. Leonards\n",
       "13  dt_5  2019-03-28  2019-07-31      leo     125  St. Leonards"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe of details\n",
    "\n",
    "# add full names to codes\n",
    "loc_full={'mar': 'Marengo',\n",
    "         'leo': 'St. Leonards'}\n",
    "\n",
    "locs_dt_str=pd.DataFrame()\n",
    "for location in dh_df.location.unique():\n",
    "   \n",
    "    df_time_tmp=dh_df.query(f\"location=='{location}'\").groupby(['dt'])[['date_pre','date_post']].first().reset_index()\n",
    "    df_time_tmp[\"orderid\"]=[int(i.split(\"_\")[1]) for i in df_time_tmp.dt]\n",
    "    df_time_tmp.sort_values([\"orderid\"], inplace=True)\n",
    "    df_time_tmp[\"location\"]=location   \n",
    "    locs_dt_str=pd.concat([df_time_tmp,locs_dt_str], ignore_index=True)\n",
    "\n",
    "# add days between dates\n",
    "deltas=[(datetime.strptime(d_to, '%Y-%m-%d') - datetime.strptime(d_from, '%Y-%m-%d')).days\n",
    "        for d_to,d_from in zip(locs_dt_str.date_post,locs_dt_str.date_pre)]\n",
    "locs_dt_str['n_days']=deltas\n",
    "\n",
    "# add full names to codes\n",
    "locs_dt_str['loc_full']=locs_dt_str.location.map(loc_full)\n",
    "\n",
    "# some cleaning and renaming\n",
    "locs_dt_str.drop('orderid',1,inplace=True)\n",
    "locs_dt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f9e4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_dt_str.to_csv(r\"C:\\my_packages\\doc_data\\profiles\\dt_info.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
